{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"OGC \u00b6 ogc - provisioning, that's it. Getting Started \u00b6 Welcome to the getting started guide! This should be a quick introduction to get up and running with OGC. More information on customizing and extending OGC can be found in the user documentation. Install \u00b6 We use and recommend the use of Poetry : $ pip install poetry $ poetry install Caution If using poetry make sure to prefix running of ogc with the following: $ poetry run ogc Optionally, load up the virtualenv beforehand: $ poetry shell Or install from pypi : $ pip install ogc Provider Setup \u00b6 OGC currently supports AWS and GCP out of the box (more added soon). In order for OGC to connect and deploy to these clouds a few environment variables are needed. Create a .env file in the top level directory where ogc is to be run: AWS_ACCESS_KEY_ID=\"\" AWS_SECRET_ACCESS_KEY=\"\" AWS_REGION=\"us-east-2\" GOOGLE_APPLICATION_CREDENTIALS=\"svc.json\" GOOGLE_APPLICATION_SERVICE_ACCOUNT=\"..@...iam.gserviceaccount.com\" GOOGLE_PROJECT=\"example-project\" GOOGLE_DATACENTER=\"us-central1-a\" Note More information can be found in our Providers documentation. Define Provisioning \u00b6 Once setup is complete, a provision layout is needed. Create a file ubuntu.py : from ogc.deployer import Deployer from ogc.log import get_logger from ogc.models import Layout from ogc.provision import choose_provisioner log = get_logger ( \"ogc\" ) layout = Layout ( instance_size = \"e2-standard-4\" , name = \"ubuntu-ogc\" , provider = \"google\" , remote_path = \"/home/ubuntu/ogc\" , runs_on = \"ubuntu-2004-lts\" , scale = 5 , scripts = \"fixtures/ex_deploy_ubuntu\" , username = \"ubuntu\" , ssh_private_key = \"~/.ssh/id_rsa_libcloud\" , ssh_public_key = \"~/.ssh/id_rsa_libcloud.pub\" , ports = [ \"22:22\" , \"80:80\" , \"443:443\" , \"5601:5601\" ], tags = [], labels = dict ( division = \"engineering\" , org = \"obs\" , team = \"observability\" , project = \"perf\" ), ) # Alternatively # from ogc.provisioner import GCEProvisioner # provisioner = GCEProvisioner(layout=layout) provisioner = choose_provisioner ( layout = layout ) deploy = Deployer . from_provisioner ( provisioner = provisioner ) def up ( ** kwargs ): deploy . up () def run ( ** kwargs ): # pass in a directory/filepath -o path=fixtures/ubuntu if kwargs . get ( \"path\" , None ): deploy . exec_scripts ( scripts = kwargs [ \"path\" ]) # pass in a cmd with -o cmd='ls -l /' elif kwargs . get ( \"cmd\" , None ): deploy . exec ( kwargs [ \"cmd\" ]) else : deploy . exec_scripts () def down ( ** kwargs ): deploy . down () This specification tells OGC to deploy 5 nodes running on Google's e2-standard-4 with Ubuntu OS. The scripts section tells OGC where the template files/scripts are located that need to be uploaded to each node during the deployment phase. Provision and Deploy \u00b6 Once the specification is set, environment variables configured, execute a deployment in a new terminal: $ ogc up ubuntu.py $ ogc run ubuntu.py -o cmd = 'sudo apt-get update && sudo apt-get dist-upgrade' $ ogc down ubuntu.py Next steps \u00b6 Learn how to manage your deployments in our User Guide - Managing a deployment","title":"Getting Started"},{"location":"#ogc","text":"ogc - provisioning, that's it.","title":"OGC"},{"location":"#getting-started","text":"Welcome to the getting started guide! This should be a quick introduction to get up and running with OGC. More information on customizing and extending OGC can be found in the user documentation.","title":"Getting Started"},{"location":"#install","text":"We use and recommend the use of Poetry : $ pip install poetry $ poetry install Caution If using poetry make sure to prefix running of ogc with the following: $ poetry run ogc Optionally, load up the virtualenv beforehand: $ poetry shell Or install from pypi : $ pip install ogc","title":"Install"},{"location":"#provider-setup","text":"OGC currently supports AWS and GCP out of the box (more added soon). In order for OGC to connect and deploy to these clouds a few environment variables are needed. Create a .env file in the top level directory where ogc is to be run: AWS_ACCESS_KEY_ID=\"\" AWS_SECRET_ACCESS_KEY=\"\" AWS_REGION=\"us-east-2\" GOOGLE_APPLICATION_CREDENTIALS=\"svc.json\" GOOGLE_APPLICATION_SERVICE_ACCOUNT=\"..@...iam.gserviceaccount.com\" GOOGLE_PROJECT=\"example-project\" GOOGLE_DATACENTER=\"us-central1-a\" Note More information can be found in our Providers documentation.","title":"Provider Setup"},{"location":"#define-provisioning","text":"Once setup is complete, a provision layout is needed. Create a file ubuntu.py : from ogc.deployer import Deployer from ogc.log import get_logger from ogc.models import Layout from ogc.provision import choose_provisioner log = get_logger ( \"ogc\" ) layout = Layout ( instance_size = \"e2-standard-4\" , name = \"ubuntu-ogc\" , provider = \"google\" , remote_path = \"/home/ubuntu/ogc\" , runs_on = \"ubuntu-2004-lts\" , scale = 5 , scripts = \"fixtures/ex_deploy_ubuntu\" , username = \"ubuntu\" , ssh_private_key = \"~/.ssh/id_rsa_libcloud\" , ssh_public_key = \"~/.ssh/id_rsa_libcloud.pub\" , ports = [ \"22:22\" , \"80:80\" , \"443:443\" , \"5601:5601\" ], tags = [], labels = dict ( division = \"engineering\" , org = \"obs\" , team = \"observability\" , project = \"perf\" ), ) # Alternatively # from ogc.provisioner import GCEProvisioner # provisioner = GCEProvisioner(layout=layout) provisioner = choose_provisioner ( layout = layout ) deploy = Deployer . from_provisioner ( provisioner = provisioner ) def up ( ** kwargs ): deploy . up () def run ( ** kwargs ): # pass in a directory/filepath -o path=fixtures/ubuntu if kwargs . get ( \"path\" , None ): deploy . exec_scripts ( scripts = kwargs [ \"path\" ]) # pass in a cmd with -o cmd='ls -l /' elif kwargs . get ( \"cmd\" , None ): deploy . exec ( kwargs [ \"cmd\" ]) else : deploy . exec_scripts () def down ( ** kwargs ): deploy . down () This specification tells OGC to deploy 5 nodes running on Google's e2-standard-4 with Ubuntu OS. The scripts section tells OGC where the template files/scripts are located that need to be uploaded to each node during the deployment phase.","title":"Define Provisioning"},{"location":"#provision-and-deploy","text":"Once the specification is set, environment variables configured, execute a deployment in a new terminal: $ ogc up ubuntu.py $ ogc run ubuntu.py -o cmd = 'sudo apt-get update && sudo apt-get dist-upgrade' $ ogc down ubuntu.py","title":"Provision and Deploy"},{"location":"#next-steps","text":"Learn how to manage your deployments in our User Guide - Managing a deployment","title":"Next steps"},{"location":"commands/ogc/","text":"CLI Reference \u00b6 This page provides documentation for our command line tool. ogc \u00b6 Manage and Provision machines Usage: ogc [OPTIONS] TASK SPEC Options: Name Type Description Default --options , -o text Pass in -o KEY=VALUE -o KEY=VALUE which is used in the provision spec None --verbose , -v boolean Turn on debug False --help boolean Show this message and exit. False","title":"CLI Reference"},{"location":"commands/ogc/#cli-reference","text":"This page provides documentation for our command line tool.","title":"CLI Reference"},{"location":"commands/ogc/#ogc","text":"Manage and Provision machines Usage: ogc [OPTIONS] TASK SPEC Options: Name Type Description Default --options , -o text Pass in -o KEY=VALUE -o KEY=VALUE which is used in the provision spec None --verbose , -v boolean Turn on debug False --help boolean Show this message and exit. False","title":"ogc"},{"location":"developer-guide/managing-nodes/","text":"Managing Nodes Programatically \u00b6 Requirements \u00b6 Accessing the functionality of OGC programatically requires that both cloud credentials and database access are configured. The environment variables for working with AWS or Google should be defined in your environment either by setting it in the .env or in the abscence of a dotenv file they can be exported by your current running shell. Using the .env is easiest and is what we'll use for the remaining documentation, the following will configure access to both AWS and Google along with defining where our Postgres database resides: AWS_ACCESS_KEY_ID = \"abbcc\" AWS_SECRET_ACCESS_KEY = \"sshitsasecret\" AWS_REGION = \"us-east-2\" GOOGLE_APPLICATION_CREDENTIALS = \"mycreds.json\" GOOGLE_APPLICATION_SERVICE_ACCOUNT = \"bob@whodunit.iam.gserviceaccount.com\" GOOGLE_PROJECT = \"my-awesome-project\" GOOGLE_DATACENTER = \"us-central1-a\" Nodes \u00b6 Once the database is setup in your code, you are ready to begin creating and managing nodes. OGC provides both synchronous and asynchronous support depending on your needs. Launch Node \u00b6 To launch a node an OGC specification is required with at least one layout defined, create a file called ubuntu.py . from ogc.deployer import Deployer from ogc.log import get_logger from ogc.models import Layout from ogc.provision import choose_provisioner layout = Layout ( instance_size = \"e2-standard-4\" , name = \"ubuntu-ogc\" , provider = \"google\" , remote_path = \"/home/ubuntu/ogc\" , runs_on = \"ubuntu-2004-lts\" , scale = 15 , scripts = \"fixtures/ex_deploy_ubuntu\" , username = \"ubuntu\" , ssh_private_key = \"~/.ssh/id_rsa_libcloud\" , ssh_public_key = \"~/.ssh/id_rsa_libcloud.pub\" , ports = [ \"22:22\" , \"80:80\" , \"443:443\" , \"5601:5601\" ], tags = [], labels = dict ( division = \"engineering\" , org = \"obs\" , team = \"observability\" , project = \"perf\" ), ) provisioner = choose_provisioner ( layout = layout ) deploy = Deployer . from_provisioner ( provisioner = provisioner ) deploy . up () deploy . exec ( cmd = 'ls -l /' ) deploy . exec_scripts () deploy . exec_scripts ( scripts = 'my/arbitrary/path' ) deploy . down () To launch this node layout: $ ogc ubuntu.py","title":"Managing nodes"},{"location":"developer-guide/managing-nodes/#managing-nodes-programatically","text":"","title":"Managing Nodes Programatically"},{"location":"developer-guide/managing-nodes/#requirements","text":"Accessing the functionality of OGC programatically requires that both cloud credentials and database access are configured. The environment variables for working with AWS or Google should be defined in your environment either by setting it in the .env or in the abscence of a dotenv file they can be exported by your current running shell. Using the .env is easiest and is what we'll use for the remaining documentation, the following will configure access to both AWS and Google along with defining where our Postgres database resides: AWS_ACCESS_KEY_ID = \"abbcc\" AWS_SECRET_ACCESS_KEY = \"sshitsasecret\" AWS_REGION = \"us-east-2\" GOOGLE_APPLICATION_CREDENTIALS = \"mycreds.json\" GOOGLE_APPLICATION_SERVICE_ACCOUNT = \"bob@whodunit.iam.gserviceaccount.com\" GOOGLE_PROJECT = \"my-awesome-project\" GOOGLE_DATACENTER = \"us-central1-a\"","title":"Requirements"},{"location":"developer-guide/managing-nodes/#nodes","text":"Once the database is setup in your code, you are ready to begin creating and managing nodes. OGC provides both synchronous and asynchronous support depending on your needs.","title":"Nodes"},{"location":"developer-guide/managing-nodes/#launch-node","text":"To launch a node an OGC specification is required with at least one layout defined, create a file called ubuntu.py . from ogc.deployer import Deployer from ogc.log import get_logger from ogc.models import Layout from ogc.provision import choose_provisioner layout = Layout ( instance_size = \"e2-standard-4\" , name = \"ubuntu-ogc\" , provider = \"google\" , remote_path = \"/home/ubuntu/ogc\" , runs_on = \"ubuntu-2004-lts\" , scale = 15 , scripts = \"fixtures/ex_deploy_ubuntu\" , username = \"ubuntu\" , ssh_private_key = \"~/.ssh/id_rsa_libcloud\" , ssh_public_key = \"~/.ssh/id_rsa_libcloud.pub\" , ports = [ \"22:22\" , \"80:80\" , \"443:443\" , \"5601:5601\" ], tags = [], labels = dict ( division = \"engineering\" , org = \"obs\" , team = \"observability\" , project = \"perf\" ), ) provisioner = choose_provisioner ( layout = layout ) deploy = Deployer . from_provisioner ( provisioner = provisioner ) deploy . up () deploy . exec ( cmd = 'ls -l /' ) deploy . exec_scripts () deploy . exec_scripts ( scripts = 'my/arbitrary/path' ) deploy . down () To launch this node layout: $ ogc ubuntu.py","title":"Launch Node"},{"location":"developer-guide/api/deployer/","text":"API \u00b6 ogc.deployer.Deployer \u00b6 Deployer The Deployer instance is responsible for bringing up nodes for a particular provisioner, whether it be AWS or Google. This also has the responsibility of uploading/downloading files to/from node(s) and facilities for executing commands or a set of scripts on the node(s). __eq__ ( self , other ) special \u00b6 Method generated by attrs for class Deployer. __getstate__ ( self ) special \u00b6 Automatically created by attrs. __init__ ( self , provisioner , db , force = False ) special \u00b6 Method generated by attrs for class Deployer. __ne__ ( self , other ) special \u00b6 Method generated by attrs for class Deployer. __repr__ ( self ) special \u00b6 Method generated by attrs for class Deployer. __setstate__ ( self , state ) special \u00b6 Automatically created by attrs. down ( self ) \u00b6 Tear down machines exec ( self , cmd ) \u00b6 Execute commands on node(s) Parameters: Name Type Description Default cmd str Command to run on node required Returns: Type Description Result[bool, Exception] True if succesful, False otherwise. exec_scripts ( self , scripts = None , filters = None ) \u00b6 Execute scripts Executing scripts/templates on a node. Parameters: Name Type Description Default scripts str The full path or directory where the scripts reside locally. Supports single file and directory. None filters Mapping[str, str] Filters to pass into exec, currently name and tag are supported. None Returns: Type Description Result[bool, str] True if succesful, False otherwise. from_provisioner ( provisioner , force = False ) classmethod \u00b6 Obtain deployer instance Parameters: Name Type Description Default provisioner BaseProvisioner AWSProvisioner | GCEProvisioner required force bool Force load False Returns: Type Description `Deployer` A deployer instance get ( self , dst , src ) \u00b6 Download file to remote node(s) Parameters: Name Type Description Default dst str Remote destination required src str The full path or directory where download files locally. required Returns: Type Description None nop. put ( self , src , dst , excludes , includes = []) \u00b6 Upload file to remote node(s) Parameters: Name Type Description Default src str The full path or directory where the scripts reside locally. required dst str Remote destination required excludes list[str] List of file patterns to exclude required includes list[str] List of file patterns to include [] Returns: Type Description None nop. up ( self ) \u00b6 Bring up machines","title":"ogc.deployer"},{"location":"developer-guide/api/deployer/#api","text":"","title":"API"},{"location":"developer-guide/api/deployer/#ogc.deployer.Deployer","text":"Deployer The Deployer instance is responsible for bringing up nodes for a particular provisioner, whether it be AWS or Google. This also has the responsibility of uploading/downloading files to/from node(s) and facilities for executing commands or a set of scripts on the node(s).","title":"Deployer"},{"location":"developer-guide/api/deployer/#ogc.deployer.Deployer.__eq__","text":"Method generated by attrs for class Deployer.","title":"__eq__()"},{"location":"developer-guide/api/deployer/#ogc.deployer.Deployer.__getstate__","text":"Automatically created by attrs.","title":"__getstate__()"},{"location":"developer-guide/api/deployer/#ogc.deployer.Deployer.__init__","text":"Method generated by attrs for class Deployer.","title":"__init__()"},{"location":"developer-guide/api/deployer/#ogc.deployer.Deployer.__ne__","text":"Method generated by attrs for class Deployer.","title":"__ne__()"},{"location":"developer-guide/api/deployer/#ogc.deployer.Deployer.__repr__","text":"Method generated by attrs for class Deployer.","title":"__repr__()"},{"location":"developer-guide/api/deployer/#ogc.deployer.Deployer.__setstate__","text":"Automatically created by attrs.","title":"__setstate__()"},{"location":"developer-guide/api/deployer/#ogc.deployer.Deployer.down","text":"Tear down machines","title":"down()"},{"location":"developer-guide/api/deployer/#ogc.deployer.Deployer.exec","text":"Execute commands on node(s) Parameters: Name Type Description Default cmd str Command to run on node required Returns: Type Description Result[bool, Exception] True if succesful, False otherwise.","title":"exec()"},{"location":"developer-guide/api/deployer/#ogc.deployer.Deployer.exec_scripts","text":"Execute scripts Executing scripts/templates on a node. Parameters: Name Type Description Default scripts str The full path or directory where the scripts reside locally. Supports single file and directory. None filters Mapping[str, str] Filters to pass into exec, currently name and tag are supported. None Returns: Type Description Result[bool, str] True if succesful, False otherwise.","title":"exec_scripts()"},{"location":"developer-guide/api/deployer/#ogc.deployer.Deployer.from_provisioner","text":"Obtain deployer instance Parameters: Name Type Description Default provisioner BaseProvisioner AWSProvisioner | GCEProvisioner required force bool Force load False Returns: Type Description `Deployer` A deployer instance","title":"from_provisioner()"},{"location":"developer-guide/api/deployer/#ogc.deployer.Deployer.get","text":"Download file to remote node(s) Parameters: Name Type Description Default dst str Remote destination required src str The full path or directory where download files locally. required Returns: Type Description None nop.","title":"get()"},{"location":"developer-guide/api/deployer/#ogc.deployer.Deployer.put","text":"Upload file to remote node(s) Parameters: Name Type Description Default src str The full path or directory where the scripts reside locally. required dst str Remote destination required excludes list[str] List of file patterns to exclude required includes list[str] List of file patterns to include [] Returns: Type Description None nop.","title":"put()"},{"location":"developer-guide/api/deployer/#ogc.deployer.Deployer.up","text":"Bring up machines","title":"up()"},{"location":"developer-guide/api/models/layout/","text":"API \u00b6 ogc.models.layout.Layout \u00b6 Layout model Synopsis: from __future__ import annotations import typing as t import rich.status from ogc.deployer import Deployer from ogc.log import get_logger from ogc.models import Layout from ogc.provision import choose_provisioner log = get_logger ( \"ogc\" ) layout = Layout ( instance_size = \"e2-standard-4\" , name = \"ubuntu-ogc\" , provider = \"google\" , remote_path = \"/home/ubuntu/ogc\" , runs_on = \"ubuntu-2004-lts\" , scale = 15 , scripts = \"fixtures/ex_deploy_ubuntu\" , username = \"ubuntu\" , ssh_private_key = \"~/.ssh/id_rsa_libcloud\" , ssh_public_key = \"~/.ssh/id_rsa_libcloud.pub\" , ports = [ \"22:22\" , \"80:80\" , \"443:443\" , \"5601:5601\" ], tags = [], labels = dict ( division = \"engineering\" , org = \"obs\" , team = \"observability\" , project = \"perf\" ), ) log . debug ( layout ) provisioner = choose_provisioner ( layout = layout ) log . debug ( provisioner ) deploy = Deployer . from_provisioner ( provisioner = provisioner ) log . debug ( deploy ) def _get_status ( ** kwargs : str ) -> rich . status . Status | None : status : \"rich.status.Status\" | None = t . cast ( rich . status . Status , kwargs . get ( \"status\" , None ) ) return status def up ( ** kwargs : str ) -> None : status = _get_status ( ** kwargs ) if status : status . start () status . update ( f \"Deploying { layout . scale } node(s) for layout: { layout . name } \" ) deploy . up () status . stop () def run ( ** kwargs : str ) -> None : if kwargs . get ( \"path\" , None ): log . info ( f \"Executing scripts path: { kwargs [ 'path' ] } \" ) deploy . exec_scripts ( scripts = kwargs [ \"path\" ]) elif kwargs . get ( \"cmd\" , None ): log . info ( f \"Executing command: { kwargs [ 'cmd' ] } \" ) deploy . exec ( kwargs [ \"cmd\" ]) else : log . info ( f \"Executing scripts path: { layout . scripts } \" ) deploy . exec_scripts () def down ( ** kwargs : str ) -> None : log . info ( f \"Teardown { deploy } - { kwargs } \" ) deploy . down () __eq__ ( self , other ) special \u00b6 Method generated by attrs for class Layout. __getstate__ ( self ) special \u00b6 Automatically created by attrs. __init__ ( self , instance_size , name , provider , remote_path , runs_on , scale , scripts , username , ssh_private_key , ssh_public_key , tags , labels = None , ports = None , arch = 'amd64' , artifacts = None , exclude = None , extra = None , include = None ) special \u00b6 Method generated by attrs for class Layout. __ne__ ( self , other ) special \u00b6 Method generated by attrs for class Layout. __repr__ ( self ) special \u00b6 Method generated by attrs for class Layout. __setattr__ ( self , name , val ) special \u00b6 Method generated by attrs for class Layout. __setstate__ ( self , state ) special \u00b6 Automatically created by attrs.","title":"ogc.models.layout"},{"location":"developer-guide/api/models/layout/#api","text":"","title":"API"},{"location":"developer-guide/api/models/layout/#ogc.models.layout.Layout","text":"Layout model Synopsis: from __future__ import annotations import typing as t import rich.status from ogc.deployer import Deployer from ogc.log import get_logger from ogc.models import Layout from ogc.provision import choose_provisioner log = get_logger ( \"ogc\" ) layout = Layout ( instance_size = \"e2-standard-4\" , name = \"ubuntu-ogc\" , provider = \"google\" , remote_path = \"/home/ubuntu/ogc\" , runs_on = \"ubuntu-2004-lts\" , scale = 15 , scripts = \"fixtures/ex_deploy_ubuntu\" , username = \"ubuntu\" , ssh_private_key = \"~/.ssh/id_rsa_libcloud\" , ssh_public_key = \"~/.ssh/id_rsa_libcloud.pub\" , ports = [ \"22:22\" , \"80:80\" , \"443:443\" , \"5601:5601\" ], tags = [], labels = dict ( division = \"engineering\" , org = \"obs\" , team = \"observability\" , project = \"perf\" ), ) log . debug ( layout ) provisioner = choose_provisioner ( layout = layout ) log . debug ( provisioner ) deploy = Deployer . from_provisioner ( provisioner = provisioner ) log . debug ( deploy ) def _get_status ( ** kwargs : str ) -> rich . status . Status | None : status : \"rich.status.Status\" | None = t . cast ( rich . status . Status , kwargs . get ( \"status\" , None ) ) return status def up ( ** kwargs : str ) -> None : status = _get_status ( ** kwargs ) if status : status . start () status . update ( f \"Deploying { layout . scale } node(s) for layout: { layout . name } \" ) deploy . up () status . stop () def run ( ** kwargs : str ) -> None : if kwargs . get ( \"path\" , None ): log . info ( f \"Executing scripts path: { kwargs [ 'path' ] } \" ) deploy . exec_scripts ( scripts = kwargs [ \"path\" ]) elif kwargs . get ( \"cmd\" , None ): log . info ( f \"Executing command: { kwargs [ 'cmd' ] } \" ) deploy . exec ( kwargs [ \"cmd\" ]) else : log . info ( f \"Executing scripts path: { layout . scripts } \" ) deploy . exec_scripts () def down ( ** kwargs : str ) -> None : log . info ( f \"Teardown { deploy } - { kwargs } \" ) deploy . down ()","title":"Layout"},{"location":"developer-guide/api/models/layout/#ogc.models.layout.Layout.__eq__","text":"Method generated by attrs for class Layout.","title":"__eq__()"},{"location":"developer-guide/api/models/layout/#ogc.models.layout.Layout.__getstate__","text":"Automatically created by attrs.","title":"__getstate__()"},{"location":"developer-guide/api/models/layout/#ogc.models.layout.Layout.__init__","text":"Method generated by attrs for class Layout.","title":"__init__()"},{"location":"developer-guide/api/models/layout/#ogc.models.layout.Layout.__ne__","text":"Method generated by attrs for class Layout.","title":"__ne__()"},{"location":"developer-guide/api/models/layout/#ogc.models.layout.Layout.__repr__","text":"Method generated by attrs for class Layout.","title":"__repr__()"},{"location":"developer-guide/api/models/layout/#ogc.models.layout.Layout.__setattr__","text":"Method generated by attrs for class Layout.","title":"__setattr__()"},{"location":"developer-guide/api/models/layout/#ogc.models.layout.Layout.__setstate__","text":"Automatically created by attrs.","title":"__setstate__()"},{"location":"developer-guide/api/models/machine/","text":"API \u00b6 ogc.models.machine.Machine \u00b6 __eq__ ( self , other ) special \u00b6 Method generated by attrs for class Machine. __getstate__ ( self ) special \u00b6 Automatically created by attrs. __init__ ( self , remote , layout , extra = None , tainted = False ) special \u00b6 Method generated by attrs for class Machine. __ne__ ( self , other ) special \u00b6 Method generated by attrs for class Machine. __repr__ ( self ) special \u00b6 Method generated by attrs for class Machine. __setstate__ ( self , state ) special \u00b6 Automatically created by attrs. from_layout ( layout , node ) classmethod \u00b6 Grabs the objects for deployment/provision ssh ( self ) \u00b6 Provides an SSH Client for use with provisioning","title":"ogc.models.machine"},{"location":"developer-guide/api/models/machine/#api","text":"","title":"API"},{"location":"developer-guide/api/models/machine/#ogc.models.machine.Machine","text":"","title":"Machine"},{"location":"developer-guide/api/models/machine/#ogc.models.machine.Machine.__eq__","text":"Method generated by attrs for class Machine.","title":"__eq__()"},{"location":"developer-guide/api/models/machine/#ogc.models.machine.Machine.__getstate__","text":"Automatically created by attrs.","title":"__getstate__()"},{"location":"developer-guide/api/models/machine/#ogc.models.machine.Machine.__init__","text":"Method generated by attrs for class Machine.","title":"__init__()"},{"location":"developer-guide/api/models/machine/#ogc.models.machine.Machine.__ne__","text":"Method generated by attrs for class Machine.","title":"__ne__()"},{"location":"developer-guide/api/models/machine/#ogc.models.machine.Machine.__repr__","text":"Method generated by attrs for class Machine.","title":"__repr__()"},{"location":"developer-guide/api/models/machine/#ogc.models.machine.Machine.__setstate__","text":"Automatically created by attrs.","title":"__setstate__()"},{"location":"developer-guide/api/models/machine/#ogc.models.machine.Machine.from_layout","text":"Grabs the objects for deployment/provision","title":"from_layout()"},{"location":"developer-guide/api/models/machine/#ogc.models.machine.Machine.ssh","text":"Provides an SSH Client for use with provisioning","title":"ssh()"},{"location":"developer-guide/api/models/utils/","text":"API \u00b6 ogc.models.utils \u00b6 init convert_tags_to_slug_tags ( tags ) \u00b6 Converts tags to their slugged equivalent serialize ( inst , field , value ) \u00b6 Serializes value into its proper type","title":"ogc.models.utils"},{"location":"developer-guide/api/models/utils/#api","text":"","title":"API"},{"location":"developer-guide/api/models/utils/#ogc.models.utils","text":"init","title":"utils"},{"location":"developer-guide/api/models/utils/#ogc.models.utils.convert_tags_to_slug_tags","text":"Converts tags to their slugged equivalent","title":"convert_tags_to_slug_tags()"},{"location":"developer-guide/api/models/utils/#ogc.models.utils.serialize","text":"Serializes value into its proper type","title":"serialize()"},{"location":"user-guide/defining-layouts/","text":"Defining Layouts \u00b6 Learn the layout specification and how to create your own provisioning layouts. Create a file ubuntu.py : from ogc.deployer import Deployer from ogc.log import get_logger from ogc.models import Layout from ogc.provision import choose_provisioner log = get_logger ( \"ogc\" ) layout = Layout ( instance_size = \"e2-standard-4\" , name = \"ubuntu-ogc\" , provider = \"google\" , remote_path = \"/home/ubuntu/ogc\" , runs_on = \"ubuntu-2004-lts\" , scale = 5 , scripts = \"fixtures/ex_deploy_ubuntu\" , username = \"ubuntu\" , ssh_private_key = \"~/.ssh/id_rsa_libcloud\" , ssh_public_key = \"~/.ssh/id_rsa_libcloud.pub\" , ports = [ \"22:22\" , \"80:80\" , \"443:443\" , \"5601:5601\" ], tags = [], labels = dict ( division = \"engineering\" , org = \"obs\" , team = \"observability\" , project = \"perf\" ), ) # Alternatively # from ogc.provisioner import GCEProvisioner # provisioner = GCEProvisioner(layout=layout) provisioner = choose_provisioner ( layout = layout ) deploy = Deployer . from_provisioner ( provisioner = provisioner ) def up ( ** kwargs ): deploy . up () def run ( ** kwargs ): # pass in a directory/filepath -o path=fixtures/ubuntu if kwargs . get ( \"path\" , None ): deploy . exec_scripts ( scripts = kwargs [ \"path\" ]) # pass in a cmd with -o cmd='ls -l /' elif kwargs . get ( \"cmd\" , None ): deploy . exec ( kwargs [ \"cmd\" ]) else : deploy . exec_scripts () def down ( ** kwargs ): deploy . down () Each layout has a friendly name associated as seen by elastic-agent-ubuntu . The next section is going to go over each option and describe its meaning. provider Define which cloud the layout will operate in. Currently supported options are aws and google . runs-on Define the base OS image to be deployed on to the nodes. The current supported list of names are: AWS Google ubuntu-2004 ubuntu-2004 ubuntu-1804 ubuntu-1804 ubuntu-1604 ubuntu-1604 sles-15 sles-15 sles-12 sles-12 sles-11 sles-11 debian-10 debian-10 debian-9 debian-9 debian-8 debian-8 rhel-8 rhel-7 rhel-6 instance-size Define the machine size, this is dependent on which provider is chosen. The instance-size correlates with the instance size naming for each cloud. For example, on AWS you would use instance-size = \"c5.4xlarge\" and in Google's case, instance-size = \"e2-standard-4\" . username The ssh user to use when deploying and accessing the nodes. This is also somewhat dependent on which provider is used. In the case of Google , any username can be given. In the case of AWS , the base machines have a pre-loaded user that must be used: AWS Username centos centos debian admin oracle ec2-user sles ec2-user ubuntu ubuntu windows 1 ogc Caution A lot of cloud machine images disable root login, try to avoid using that as a user and utilize sudo for anything requiring elevated permissions. scripts The location on your machine where templates/scripts resides. These will be uploaded and executed during the deployment phase. Note See scripting for more information. scale How many nodes of each layout to deploy. This is also referenced during a deployment reconciliation phase. remote-path (optional) If set, any uploads/downloads outside of what's defined in scripts will be placed in that remote path. include (optional) A list of files/wildcards to include in the upload exclude (optional) A list of files/wildcards to exclude in the upload artifacts (optional) The remote path where script execution output is stored. This is used when pulling artifacts with ogc pull-artifacts and also utilized during node teardown. This will download any artifacts found into artifacts/instance-name/ . tags (optional) Define tags for each layout, allows additional filtering capabilities and deployment options when used with ogc ls and ogc exec ports (optional) Define what ingress ports are available when accessing the node. This is the default user for our contributed packer build for Windows \u21a9","title":"Defining Layouts"},{"location":"user-guide/defining-layouts/#defining-layouts","text":"Learn the layout specification and how to create your own provisioning layouts. Create a file ubuntu.py : from ogc.deployer import Deployer from ogc.log import get_logger from ogc.models import Layout from ogc.provision import choose_provisioner log = get_logger ( \"ogc\" ) layout = Layout ( instance_size = \"e2-standard-4\" , name = \"ubuntu-ogc\" , provider = \"google\" , remote_path = \"/home/ubuntu/ogc\" , runs_on = \"ubuntu-2004-lts\" , scale = 5 , scripts = \"fixtures/ex_deploy_ubuntu\" , username = \"ubuntu\" , ssh_private_key = \"~/.ssh/id_rsa_libcloud\" , ssh_public_key = \"~/.ssh/id_rsa_libcloud.pub\" , ports = [ \"22:22\" , \"80:80\" , \"443:443\" , \"5601:5601\" ], tags = [], labels = dict ( division = \"engineering\" , org = \"obs\" , team = \"observability\" , project = \"perf\" ), ) # Alternatively # from ogc.provisioner import GCEProvisioner # provisioner = GCEProvisioner(layout=layout) provisioner = choose_provisioner ( layout = layout ) deploy = Deployer . from_provisioner ( provisioner = provisioner ) def up ( ** kwargs ): deploy . up () def run ( ** kwargs ): # pass in a directory/filepath -o path=fixtures/ubuntu if kwargs . get ( \"path\" , None ): deploy . exec_scripts ( scripts = kwargs [ \"path\" ]) # pass in a cmd with -o cmd='ls -l /' elif kwargs . get ( \"cmd\" , None ): deploy . exec ( kwargs [ \"cmd\" ]) else : deploy . exec_scripts () def down ( ** kwargs ): deploy . down () Each layout has a friendly name associated as seen by elastic-agent-ubuntu . The next section is going to go over each option and describe its meaning. provider Define which cloud the layout will operate in. Currently supported options are aws and google . runs-on Define the base OS image to be deployed on to the nodes. The current supported list of names are: AWS Google ubuntu-2004 ubuntu-2004 ubuntu-1804 ubuntu-1804 ubuntu-1604 ubuntu-1604 sles-15 sles-15 sles-12 sles-12 sles-11 sles-11 debian-10 debian-10 debian-9 debian-9 debian-8 debian-8 rhel-8 rhel-7 rhel-6 instance-size Define the machine size, this is dependent on which provider is chosen. The instance-size correlates with the instance size naming for each cloud. For example, on AWS you would use instance-size = \"c5.4xlarge\" and in Google's case, instance-size = \"e2-standard-4\" . username The ssh user to use when deploying and accessing the nodes. This is also somewhat dependent on which provider is used. In the case of Google , any username can be given. In the case of AWS , the base machines have a pre-loaded user that must be used: AWS Username centos centos debian admin oracle ec2-user sles ec2-user ubuntu ubuntu windows 1 ogc Caution A lot of cloud machine images disable root login, try to avoid using that as a user and utilize sudo for anything requiring elevated permissions. scripts The location on your machine where templates/scripts resides. These will be uploaded and executed during the deployment phase. Note See scripting for more information. scale How many nodes of each layout to deploy. This is also referenced during a deployment reconciliation phase. remote-path (optional) If set, any uploads/downloads outside of what's defined in scripts will be placed in that remote path. include (optional) A list of files/wildcards to include in the upload exclude (optional) A list of files/wildcards to exclude in the upload artifacts (optional) The remote path where script execution output is stored. This is used when pulling artifacts with ogc pull-artifacts and also utilized during node teardown. This will download any artifacts found into artifacts/instance-name/ . tags (optional) Define tags for each layout, allows additional filtering capabilities and deployment options when used with ogc ls and ogc exec ports (optional) Define what ingress ports are available when accessing the node. This is the default user for our contributed packer build for Windows \u21a9","title":"Defining Layouts"},{"location":"user-guide/managing-nodes/","text":"Managing a Deployment \u00b6 Learn how to list, inspect, access and debug your node deployments. Listing Nodes \u00b6 To list nodes in your deployment, run the following: $ ogc ls ubuntu.py Which gives a table output of current node deployments: Accessing nodes \u00b6 OGC provides a helper command for easily accessing any of the nodes in your deployment. To login to a node run: $ ogc ssh ogc-d7cd61a7-elastic-agent-ubuntu ... ssh output ... ogc@ogc-d7cd61a7-elastic-agent-ubuntu:~# Executing commands \u00b6 Running arbitrary commands can be accomplished with: $ ogc exec ubuntu.py 'ls -l /' Executing a scripts directory \u00b6 In addition to running arbitrary commands, OGC can also execute a directory of templates/scripts: $ ogc exec-scripts ubuntu.py fixtures/ex_deploy_ubuntu This can be useful to re-run a deployment or add new functionality/one-offs to a node without disturbing the original layout specifications. Access to the database and all templating is available as well. Destroying nodes \u00b6 OGC allows destroying of individual or a full blown cleanup. To remove a single node we run: $ ogc down ubuntu.py --force","title":"Managing a deployment"},{"location":"user-guide/managing-nodes/#managing-a-deployment","text":"Learn how to list, inspect, access and debug your node deployments.","title":"Managing a Deployment"},{"location":"user-guide/managing-nodes/#listing-nodes","text":"To list nodes in your deployment, run the following: $ ogc ls ubuntu.py Which gives a table output of current node deployments:","title":"Listing Nodes"},{"location":"user-guide/managing-nodes/#accessing-nodes","text":"OGC provides a helper command for easily accessing any of the nodes in your deployment. To login to a node run: $ ogc ssh ogc-d7cd61a7-elastic-agent-ubuntu ... ssh output ... ogc@ogc-d7cd61a7-elastic-agent-ubuntu:~#","title":"Accessing nodes"},{"location":"user-guide/managing-nodes/#executing-commands","text":"Running arbitrary commands can be accomplished with: $ ogc exec ubuntu.py 'ls -l /'","title":"Executing commands"},{"location":"user-guide/managing-nodes/#executing-a-scripts-directory","text":"In addition to running arbitrary commands, OGC can also execute a directory of templates/scripts: $ ogc exec-scripts ubuntu.py fixtures/ex_deploy_ubuntu This can be useful to re-run a deployment or add new functionality/one-offs to a node without disturbing the original layout specifications. Access to the database and all templating is available as well.","title":"Executing a scripts directory"},{"location":"user-guide/managing-nodes/#destroying-nodes","text":"OGC allows destroying of individual or a full blown cleanup. To remove a single node we run: $ ogc down ubuntu.py --force","title":"Destroying nodes"},{"location":"user-guide/providers/","text":"Providers \u00b6 In order to access a cloud provider, there are certain environment variables that need to be exposed for each. Each environment variable should be defined in .env file so it will be automatically loaded when running OGC. AWS \u00b6 AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY AWS_REGION Google \u00b6 GOOGLE_APPLICATION_CREDENTIALS GOOGLE_APPLICATION_SERVICE_ACCOUNT GOOGLE_PROJECT GOOGLE_DATACENTER","title":"Providers"},{"location":"user-guide/providers/#providers","text":"In order to access a cloud provider, there are certain environment variables that need to be exposed for each. Each environment variable should be defined in .env file so it will be automatically loaded when running OGC.","title":"Providers"},{"location":"user-guide/providers/#aws","text":"AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY AWS_REGION","title":"AWS"},{"location":"user-guide/providers/#google","text":"GOOGLE_APPLICATION_CREDENTIALS GOOGLE_APPLICATION_SERVICE_ACCOUNT GOOGLE_PROJECT GOOGLE_DATACENTER","title":"Google"},{"location":"user-guide/scripting/","text":"Scripting \u00b6 All deployments have the ability to execute scripts once a node becomes available. Before starting \u00b6 A couple of things to keep in mind: All scripts are executed in order based on the filenames. It is recommended to create scripts with a numbered prefix, for example: - scripts/ - 01-install-deps - 02-configure-services There is a special reserved filename teardown , if this file exists it will only be executed during a removal of a node. This is useful for any cleanup actions that may need to be run, such as removing test users, un-enrolling from a service, etc. Writing scripts \u00b6 Scripts can be written in any language, it is up to you to configure the nodes so that any runtimes and library dependencies are met on the target node for your script to execute in. One way to accomplish this is to create 01-setup-env bash script: #!/bin/bash echo \"Installing python3 on ubuntu\" sudo apt-get update sudo apt-get install -qyf python3 sudo pip install sh Then in subsequent scripts, using python3 is available. For example, in file 02-run-cmd-in-python : #!/usr/bin/env python3 import sh sh . ls ( '/' ) sh . cp ( '-a' , 'mydir' , 'anotherdir' ) Templating \u00b6 OGC provides some additional capabilities through templating. Under the hood python-mako is used for the parsing. With templating, you have the ability to query the underlying database to gather node information, a couple of modules are already exposed in the templates context: Var Description db Exposes access to the database node Current deployed node metadata env Environment variables are made available through this key, env['USER'] #!/bin/bash <%! from ogc.templatetags import run, header, hr %> <%namespace name = \"utils\" file = \"/functions.mako\" /> ${ header ( 'Connection information' ) } echo \"id: ${ node .instance_id } \" echo \"name: ${ node .instance_name } \" echo \"connection: ${ node .layout.username } @ ${ node .public_ip } \" echo \"provider ${ node .layout.provider } \" ${ hr () } ${ run ( 'ls' , '/' , l=True, h=True) } ${ header ( 'All nodes' ) } % for obj in db.nodes () .values () : echo \"id: ${ obj .instance_id } \" echo \"name: ${ obj .instance_name } \" echo \"connection: ${ obj .layout.username } @ ${ obj .public_ip } \" echo \"provider ${ obj .layout.provider } \" % endfor ${ header ( 'All nodes finished' ) } ${ run ( 'mkdir' , node.layout.remote_path + \"/output\" , p=True) } && \\ ${ run ( 'touch' , node.layout.remote_path + \"/output/test.xml\" ) } The runtime environment is also available within the template context. Note Any environment variables exported within OGC will be exposed in the templates. Reusable helpers \u00b6 In the above example we reference a file called /functions.mako this is just another template file that sits just outside of our defined scripts , for example, if our scripts is defined to be in scripts/my_ubuntu_deploy then this functions.mako will live at scripts/functions.mako . Alert This is good practice as you may have multiple layouts with different script directories for each and would like to store common functionality in a single place. Defining helper functions is straight forward, lets look at functions.mako for an example: ## Helper template functions downloading/extracting files <%def name = \"setup_env()\" > if ! test -f \"/usr/local/bin/pacapt\" ; then wget -O /usr/local/bin/pacapt https://github.com/icy/pacapt/raw/ng/pacapt chmod 755 /usr/local/bin/pacapt ln -sv /usr/local/bin/pacapt /usr/local/bin/pacman || true fi </%def> <%def name = \"install_pkgs(pkgs)\" > % for pkg in pkgs: pacapt install --noconfirm ${ pkg } % endfor </%def> <%def name = \"download(url, src_file)\" > wget -O ${ src_file } ${ url } </%def> <%def name = \"extract(src, dst=None)\" > % if dst: mkdir -p ${ dst } tar -xvf ${ src } -C ${ dst } % else : tar -xvf ${ src } % endif </%def> Each %def section defines a function block that when called with any necessary arguments will output that data into the scripts with all necessary translations handled. You can see the usage of these functions in the previous example for installing elastic-agent. It is worth the time to visit Mako's website and learn about its feature set, particularly namespaces and defs and blocks .","title":"Scripting"},{"location":"user-guide/scripting/#scripting","text":"All deployments have the ability to execute scripts once a node becomes available.","title":"Scripting"},{"location":"user-guide/scripting/#before-starting","text":"A couple of things to keep in mind: All scripts are executed in order based on the filenames. It is recommended to create scripts with a numbered prefix, for example: - scripts/ - 01-install-deps - 02-configure-services There is a special reserved filename teardown , if this file exists it will only be executed during a removal of a node. This is useful for any cleanup actions that may need to be run, such as removing test users, un-enrolling from a service, etc.","title":"Before starting"},{"location":"user-guide/scripting/#writing-scripts","text":"Scripts can be written in any language, it is up to you to configure the nodes so that any runtimes and library dependencies are met on the target node for your script to execute in. One way to accomplish this is to create 01-setup-env bash script: #!/bin/bash echo \"Installing python3 on ubuntu\" sudo apt-get update sudo apt-get install -qyf python3 sudo pip install sh Then in subsequent scripts, using python3 is available. For example, in file 02-run-cmd-in-python : #!/usr/bin/env python3 import sh sh . ls ( '/' ) sh . cp ( '-a' , 'mydir' , 'anotherdir' )","title":"Writing scripts"},{"location":"user-guide/scripting/#templating","text":"OGC provides some additional capabilities through templating. Under the hood python-mako is used for the parsing. With templating, you have the ability to query the underlying database to gather node information, a couple of modules are already exposed in the templates context: Var Description db Exposes access to the database node Current deployed node metadata env Environment variables are made available through this key, env['USER'] #!/bin/bash <%! from ogc.templatetags import run, header, hr %> <%namespace name = \"utils\" file = \"/functions.mako\" /> ${ header ( 'Connection information' ) } echo \"id: ${ node .instance_id } \" echo \"name: ${ node .instance_name } \" echo \"connection: ${ node .layout.username } @ ${ node .public_ip } \" echo \"provider ${ node .layout.provider } \" ${ hr () } ${ run ( 'ls' , '/' , l=True, h=True) } ${ header ( 'All nodes' ) } % for obj in db.nodes () .values () : echo \"id: ${ obj .instance_id } \" echo \"name: ${ obj .instance_name } \" echo \"connection: ${ obj .layout.username } @ ${ obj .public_ip } \" echo \"provider ${ obj .layout.provider } \" % endfor ${ header ( 'All nodes finished' ) } ${ run ( 'mkdir' , node.layout.remote_path + \"/output\" , p=True) } && \\ ${ run ( 'touch' , node.layout.remote_path + \"/output/test.xml\" ) } The runtime environment is also available within the template context. Note Any environment variables exported within OGC will be exposed in the templates.","title":"Templating"},{"location":"user-guide/scripting/#reusable-helpers","text":"In the above example we reference a file called /functions.mako this is just another template file that sits just outside of our defined scripts , for example, if our scripts is defined to be in scripts/my_ubuntu_deploy then this functions.mako will live at scripts/functions.mako . Alert This is good practice as you may have multiple layouts with different script directories for each and would like to store common functionality in a single place. Defining helper functions is straight forward, lets look at functions.mako for an example: ## Helper template functions downloading/extracting files <%def name = \"setup_env()\" > if ! test -f \"/usr/local/bin/pacapt\" ; then wget -O /usr/local/bin/pacapt https://github.com/icy/pacapt/raw/ng/pacapt chmod 755 /usr/local/bin/pacapt ln -sv /usr/local/bin/pacapt /usr/local/bin/pacman || true fi </%def> <%def name = \"install_pkgs(pkgs)\" > % for pkg in pkgs: pacapt install --noconfirm ${ pkg } % endfor </%def> <%def name = \"download(url, src_file)\" > wget -O ${ src_file } ${ url } </%def> <%def name = \"extract(src, dst=None)\" > % if dst: mkdir -p ${ dst } tar -xvf ${ src } -C ${ dst } % else : tar -xvf ${ src } % endif </%def> Each %def section defines a function block that when called with any necessary arguments will output that data into the scripts with all necessary translations handled. You can see the usage of these functions in the previous example for installing elastic-agent. It is worth the time to visit Mako's website and learn about its feature set, particularly namespaces and defs and blocks .","title":"Reusable helpers"},{"location":"user-guide/windows/","text":"Windows \u00b6 OGC supports provisioning Windows instances, however, it does make a couple of assumptions: OpenSSH Server is running on the Windows Machine Rsync is installed and available Passwordless ssh is setup Fortunately, we provide you with a Packer setup that will let you quickly build an AWS AMI to meet those requirements. Warning If using OGC contributed packer build, only AWS is supported at this time. Build AMI \u00b6 The configurations are located in contrib/ , to get started run: $ git clone https://github.com/adam-stokes/ogc $ cd ogc/contrib Alert If using these Packer configs, please note the default user to use is: ogc Windows 2019 \u00b6 To build a Windows 2019 Server instance run: ogc/contrib> $ packer build windows2019.json Once complete, grab the AMI ID, as this will be used in the layout specification of OGC. Usage \u00b6 To provision and deploy a Windows machine, the following example spec will work: Create a file windows.py : from ogc.deployer import Deployer from ogc.log import get_logger from ogc.models import Layout from ogc.provision import choose_provisioner log = get_logger ( \"ogc\" ) layout = Layout ( instance_size = \"c5.2xlarge\" , name = \"ubuntu-ogc\" , provider = \"aws\" , remote_path = \"ogc-src\" , runs_on = \"ami-0587bd602f1da2f1d\" , scale = 1 , scripts = \"fixtures/ex_deploy_windows\" , username = \"ogc\" , ssh_private_key = \"~/.ssh/id_rsa_libcloud\" , ssh_public_key = \"~/.ssh/id_rsa_libcloud.pub\" , ports = [ \"22:22\" , \"80:80\" , \"443:443\" , \"5601:5601\" ], tags = [], labels = dict ( division = \"engineering\" , org = \"obs\" , team = \"observability\" , project = \"perf\" ), ) # Alternatively # from ogc.provisioner import GCEProvisioner # provisioner = GCEProvisioner(layout=layout) provisioner = choose_provisioner ( layout = layout ) deploy = Deployer . from_provisioner ( provisioner = provisioner ) def up ( ** kwargs ): deploy . up () def run ( ** kwargs ): # pass in a directory/filepath -o path=fixtures/ubuntu if kwargs . get ( \"path\" , None ): deploy . exec_scripts ( scripts = kwargs [ \"path\" ]) # pass in a cmd with -o cmd='ls -l /' elif kwargs . get ( \"cmd\" , None ): deploy . exec ( kwargs [ \"cmd\" ]) else : deploy . exec_scripts () def down ( ** kwargs ): deploy . down () Once defined, simply running: $ ogc up windows.py Will get you a provisioned Windows machine! Scripting \u00b6 Powershell a good choice, works out of the box on Windows, however, if you want to use a different programming language the choice is yours. All the templating, database, and context is available. For example, to print out the current node information, edit a file 01-powershell : powershell echo \"${node.instance_name}:${node.public_ip}\" > ${node.instance_name}.txt This is a simple example, for a more advanced deployment it may be best to create your ps1 files and then reference them through powershell interpreter.","title":"Windows"},{"location":"user-guide/windows/#windows","text":"OGC supports provisioning Windows instances, however, it does make a couple of assumptions: OpenSSH Server is running on the Windows Machine Rsync is installed and available Passwordless ssh is setup Fortunately, we provide you with a Packer setup that will let you quickly build an AWS AMI to meet those requirements. Warning If using OGC contributed packer build, only AWS is supported at this time.","title":"Windows"},{"location":"user-guide/windows/#build-ami","text":"The configurations are located in contrib/ , to get started run: $ git clone https://github.com/adam-stokes/ogc $ cd ogc/contrib Alert If using these Packer configs, please note the default user to use is: ogc","title":"Build AMI"},{"location":"user-guide/windows/#windows-2019","text":"To build a Windows 2019 Server instance run: ogc/contrib> $ packer build windows2019.json Once complete, grab the AMI ID, as this will be used in the layout specification of OGC.","title":"Windows 2019"},{"location":"user-guide/windows/#usage","text":"To provision and deploy a Windows machine, the following example spec will work: Create a file windows.py : from ogc.deployer import Deployer from ogc.log import get_logger from ogc.models import Layout from ogc.provision import choose_provisioner log = get_logger ( \"ogc\" ) layout = Layout ( instance_size = \"c5.2xlarge\" , name = \"ubuntu-ogc\" , provider = \"aws\" , remote_path = \"ogc-src\" , runs_on = \"ami-0587bd602f1da2f1d\" , scale = 1 , scripts = \"fixtures/ex_deploy_windows\" , username = \"ogc\" , ssh_private_key = \"~/.ssh/id_rsa_libcloud\" , ssh_public_key = \"~/.ssh/id_rsa_libcloud.pub\" , ports = [ \"22:22\" , \"80:80\" , \"443:443\" , \"5601:5601\" ], tags = [], labels = dict ( division = \"engineering\" , org = \"obs\" , team = \"observability\" , project = \"perf\" ), ) # Alternatively # from ogc.provisioner import GCEProvisioner # provisioner = GCEProvisioner(layout=layout) provisioner = choose_provisioner ( layout = layout ) deploy = Deployer . from_provisioner ( provisioner = provisioner ) def up ( ** kwargs ): deploy . up () def run ( ** kwargs ): # pass in a directory/filepath -o path=fixtures/ubuntu if kwargs . get ( \"path\" , None ): deploy . exec_scripts ( scripts = kwargs [ \"path\" ]) # pass in a cmd with -o cmd='ls -l /' elif kwargs . get ( \"cmd\" , None ): deploy . exec ( kwargs [ \"cmd\" ]) else : deploy . exec_scripts () def down ( ** kwargs ): deploy . down () Once defined, simply running: $ ogc up windows.py Will get you a provisioned Windows machine!","title":"Usage"},{"location":"user-guide/windows/#scripting","text":"Powershell a good choice, works out of the box on Windows, however, if you want to use a different programming language the choice is yours. All the templating, database, and context is available. For example, to print out the current node information, edit a file 01-powershell : powershell echo \"${node.instance_name}:${node.public_ip}\" > ${node.instance_name}.txt This is a simple example, for a more advanced deployment it may be best to create your ps1 files and then reference them through powershell interpreter.","title":"Scripting"},{"location":"user-guide/cookbook/template-access-node-info/","text":"Accessing node information \u00b6 Current node \u00b6 In template files you have access to the node that is currently being rendered prior to those scripts being uploaded. Below is an example of querying the current node's information and outputting it to a file: #!/bin/bash echo \"### CURRENT NODE\" >> node_info.txt echo \"[ID: ${ node .id } ] Name: ${ node .instance_name } || Connection: ${ node .username } @ ${ node .public_ip } || Provider: ${ node .provider } \" >> node_info.txt echo \"### CURRENT NODE\" >> node_info.txt Save this file in the location of your defined scripts and give it a indexed name of where in the order it should be executed, for example, 01-show-node-info 1 . All nodes \u00b6 In some cases you may need to grab information from another node in the deployment, for example, a second node running Kibana in which the first node needs to perform some kind of API calls against it. We can accomplish this using the db and modules that's exposed in our templates. Create a file 02-curl-remote with the following: #!/bin/bash sudo pip install httpie KIBANA_HOST = ${ node .instance_name.contains([ \"kibana\" ]).first() or '' ) } http -a username:passsword -f GET https:// $KIBANA_HOST :5601/fleet/setup kbn-xsrf:ogc See the Scripting documentation for ordering of files. \u21a9","title":"Access node info"},{"location":"user-guide/cookbook/template-access-node-info/#accessing-node-information","text":"","title":"Accessing node information"},{"location":"user-guide/cookbook/template-access-node-info/#current-node","text":"In template files you have access to the node that is currently being rendered prior to those scripts being uploaded. Below is an example of querying the current node's information and outputting it to a file: #!/bin/bash echo \"### CURRENT NODE\" >> node_info.txt echo \"[ID: ${ node .id } ] Name: ${ node .instance_name } || Connection: ${ node .username } @ ${ node .public_ip } || Provider: ${ node .provider } \" >> node_info.txt echo \"### CURRENT NODE\" >> node_info.txt Save this file in the location of your defined scripts and give it a indexed name of where in the order it should be executed, for example, 01-show-node-info 1 .","title":"Current node"},{"location":"user-guide/cookbook/template-access-node-info/#all-nodes","text":"In some cases you may need to grab information from another node in the deployment, for example, a second node running Kibana in which the first node needs to perform some kind of API calls against it. We can accomplish this using the db and modules that's exposed in our templates. Create a file 02-curl-remote with the following: #!/bin/bash sudo pip install httpie KIBANA_HOST = ${ node .instance_name.contains([ \"kibana\" ]).first() or '' ) } http -a username:passsword -f GET https:// $KIBANA_HOST :5601/fleet/setup kbn-xsrf:ogc See the Scripting documentation for ordering of files. \u21a9","title":"All nodes"}]}