{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"OGC \u00b6 ogc - provisioning, that\u2019s it. Getting Started \u00b6 Welcome to the getting started guide! This should be a quick introduction to get up and running with OGC. More information on customizing and extending OGC can be found in the user documentation. Setup \u00b6 OGC requires Postgres to function. The easiest way to fulfill this requirement is with docker-compose : version : \"3.9\" services : postgres : image : postgres:11 environment : - POSTGRES_DB=ogc - POSTGRES_USER=postgres - POSTGRES_PASSWORD=postgres healthcheck : test : [ \"CMD\" , \"pg_isready\" , \"-U\" , \"postgres\" ] retries : 300 interval : 1s ports : - '5432:5432' Bring up the services $ docker-compose up Info To connect to a remote postgres database export the following environment variables POSTGRES_HOST POSTGRES_PORT POSTGRES_DB POSTGRES_USER POSTGRES_PASSWORD Next , is installation of OGC. We use Poetry : $ pip install poetry $ poetry install Caution If using poetry make sure to prefix running of ogc with the following: $ poetry run ogc Optionally, load up the virtualenv beforehand: $ poetry shell Or install from pypi : $ pip install ogc Initialize \u00b6 Next is to initialize the OGC environment, to do that run: $ ogc init It will ask you for a name, feel free to put something other than your actual name if desired. Provider Setup \u00b6 OGC currently supports AWS and GCP out of the box (more added soon). In order for OGC to connect and deploy to these clouds a few environment variables are needed. Create a .env file in the top level directory where ogc is to be run: AWS_ACCESS_KEY_ID=\"\" AWS_SECRET_ACCESS_KEY=\"\" AWS_REGION=\"us-east-2\" GOOGLE_APPLICATION_CREDENTIALS=\"svc.json\" GOOGLE_APPLICATION_SERVICE_ACCOUNT=\"..@...iam.gserviceaccount.com\" GOOGLE_PROJECT=\"example-project\" GOOGLE_DATACENTER=\"us-central1-a\" Note More information can be found in our Providers documentation. Define Provisioning \u00b6 Once setup is complete, a provision specification is needed. This defines ssh-keys and one or more layouts to be provisioned. Create a file ogc.yml and place in the top level directory where ogc is run: name : ci # SSH Keys must be passwordless ssh-keys : public : ~/.ssh/id_rsa_libcloud.pub private : ~/.ssh/id_rsa_libcloud layouts : elastic-agent-sles : runs-on : sles-15 instance-size : e2-standard-8 username : root scripts : fixtures/ex_deploy_sles provider : google scale : 5 remote-path : /root/ogc include : - .ogc-cache exclude : - .git - .venv artifacts : /root/output/*.xml tags : - elastic-agent-8.1.x - sles-gcp This specification tells OGC to deploy 5 nodes running on Google\u2019s e2-standard-8 with SUSE 15 OS. The scripts section tells OGC where the template files/scripts are located that need to be uploaded to each node during the deployment phase. Provision and Deploy \u00b6 Once the specification is set, environment variables configured and a postgres database is accessible, execute a deployment in a new terminal: $ ogc launch Note If the file is something other than ogc.yml append the --spec option to the launch command: $ ogc launch --spec my-custom-provision.yml Next steps \u00b6 Learn how to manage your deployments in our User Guide - Managing a deployment","title":"Getting Started"},{"location":"#ogc","text":"ogc - provisioning, that\u2019s it.","title":"OGC"},{"location":"#getting-started","text":"Welcome to the getting started guide! This should be a quick introduction to get up and running with OGC. More information on customizing and extending OGC can be found in the user documentation.","title":"Getting Started"},{"location":"#setup","text":"OGC requires Postgres to function. The easiest way to fulfill this requirement is with docker-compose : version : \"3.9\" services : postgres : image : postgres:11 environment : - POSTGRES_DB=ogc - POSTGRES_USER=postgres - POSTGRES_PASSWORD=postgres healthcheck : test : [ \"CMD\" , \"pg_isready\" , \"-U\" , \"postgres\" ] retries : 300 interval : 1s ports : - '5432:5432' Bring up the services $ docker-compose up Info To connect to a remote postgres database export the following environment variables POSTGRES_HOST POSTGRES_PORT POSTGRES_DB POSTGRES_USER POSTGRES_PASSWORD Next , is installation of OGC. We use Poetry : $ pip install poetry $ poetry install Caution If using poetry make sure to prefix running of ogc with the following: $ poetry run ogc Optionally, load up the virtualenv beforehand: $ poetry shell Or install from pypi : $ pip install ogc","title":"Setup"},{"location":"#initialize","text":"Next is to initialize the OGC environment, to do that run: $ ogc init It will ask you for a name, feel free to put something other than your actual name if desired.","title":"Initialize"},{"location":"#provider-setup","text":"OGC currently supports AWS and GCP out of the box (more added soon). In order for OGC to connect and deploy to these clouds a few environment variables are needed. Create a .env file in the top level directory where ogc is to be run: AWS_ACCESS_KEY_ID=\"\" AWS_SECRET_ACCESS_KEY=\"\" AWS_REGION=\"us-east-2\" GOOGLE_APPLICATION_CREDENTIALS=\"svc.json\" GOOGLE_APPLICATION_SERVICE_ACCOUNT=\"..@...iam.gserviceaccount.com\" GOOGLE_PROJECT=\"example-project\" GOOGLE_DATACENTER=\"us-central1-a\" Note More information can be found in our Providers documentation.","title":"Provider Setup"},{"location":"#define-provisioning","text":"Once setup is complete, a provision specification is needed. This defines ssh-keys and one or more layouts to be provisioned. Create a file ogc.yml and place in the top level directory where ogc is run: name : ci # SSH Keys must be passwordless ssh-keys : public : ~/.ssh/id_rsa_libcloud.pub private : ~/.ssh/id_rsa_libcloud layouts : elastic-agent-sles : runs-on : sles-15 instance-size : e2-standard-8 username : root scripts : fixtures/ex_deploy_sles provider : google scale : 5 remote-path : /root/ogc include : - .ogc-cache exclude : - .git - .venv artifacts : /root/output/*.xml tags : - elastic-agent-8.1.x - sles-gcp This specification tells OGC to deploy 5 nodes running on Google\u2019s e2-standard-8 with SUSE 15 OS. The scripts section tells OGC where the template files/scripts are located that need to be uploaded to each node during the deployment phase.","title":"Define Provisioning"},{"location":"#provision-and-deploy","text":"Once the specification is set, environment variables configured and a postgres database is accessible, execute a deployment in a new terminal: $ ogc launch Note If the file is something other than ogc.yml append the --spec option to the launch command: $ ogc launch --spec my-custom-provision.yml","title":"Provision and Deploy"},{"location":"#next-steps","text":"Learn how to manage your deployments in our User Guide - Managing a deployment","title":"Next steps"},{"location":"commands/ogc-db-migrate/","text":"NAME \u00b6 ogc-db-migrate - Database migrations SYNOPSIS \u00b6 ogc db-migrate [OPTIONS] DESCRIPTION \u00b6 Database migrations","title":"ogc db-migrate"},{"location":"commands/ogc-db-migrate/#name","text":"ogc-db-migrate - Database migrations","title":"NAME"},{"location":"commands/ogc-db-migrate/#synopsis","text":"ogc db-migrate [OPTIONS]","title":"SYNOPSIS"},{"location":"commands/ogc-db-migrate/#description","text":"Database migrations","title":"DESCRIPTION"},{"location":"commands/ogc-exec-scripts/","text":"NAME \u00b6 ogc-exec-scripts - (R)Execute a set of scripts SYNOPSIS \u00b6 ogc exec-scripts [OPTIONS] PATH DESCRIPTION \u00b6 (R)Execute a set of scripts OPTIONS \u00b6 --by-tag TEXT : Only run on nodes matching tag --by-name TEXT : Only run on nodes matching name","title":"ogc exec-scripts"},{"location":"commands/ogc-exec-scripts/#name","text":"ogc-exec-scripts - (R)Execute a set of scripts","title":"NAME"},{"location":"commands/ogc-exec-scripts/#synopsis","text":"ogc exec-scripts [OPTIONS] PATH","title":"SYNOPSIS"},{"location":"commands/ogc-exec-scripts/#description","text":"(R)Execute a set of scripts","title":"DESCRIPTION"},{"location":"commands/ogc-exec-scripts/#options","text":"--by-tag TEXT : Only run on nodes matching tag --by-name TEXT : Only run on nodes matching name","title":"OPTIONS"},{"location":"commands/ogc-exec/","text":"NAME \u00b6 ogc-exec - Execute a command across node(s) SYNOPSIS \u00b6 ogc exec [OPTIONS] CMD DESCRIPTION \u00b6 Execute a command across node(s) OPTIONS \u00b6 --by-tag TEXT : Only run on nodes matching tag --by-name TEXT : Only run on nodes matching name","title":"ogc exec"},{"location":"commands/ogc-exec/#name","text":"ogc-exec - Execute a command across node(s)","title":"NAME"},{"location":"commands/ogc-exec/#synopsis","text":"ogc exec [OPTIONS] CMD","title":"SYNOPSIS"},{"location":"commands/ogc-exec/#description","text":"Execute a command across node(s)","title":"DESCRIPTION"},{"location":"commands/ogc-exec/#options","text":"--by-tag TEXT : Only run on nodes matching tag --by-name TEXT : Only run on nodes matching name","title":"OPTIONS"},{"location":"commands/ogc-init/","text":"NAME \u00b6 ogc-init - Initialize OGC SYNOPSIS \u00b6 ogc init [OPTIONS] DESCRIPTION \u00b6 Initialize OGC","title":"ogc init"},{"location":"commands/ogc-init/#name","text":"ogc-init - Initialize OGC","title":"NAME"},{"location":"commands/ogc-init/#synopsis","text":"ogc init [OPTIONS]","title":"SYNOPSIS"},{"location":"commands/ogc-init/#description","text":"Initialize OGC","title":"DESCRIPTION"},{"location":"commands/ogc-inspect/","text":"NAME \u00b6 ogc-inspect - List nodes in your inventory SYNOPSIS \u00b6 ogc inspect [OPTIONS] DESCRIPTION \u00b6 List nodes in your inventory OPTIONS \u00b6 --id TEXT : Inspect node by DB ID --name TEXT : Inspect nodes by name, this can be a substring match --tag TEXT : Inspect nodes by tag --action-id TEXT : If set will only show the action output for a specific action ID","title":"ogc inspect"},{"location":"commands/ogc-inspect/#name","text":"ogc-inspect - List nodes in your inventory","title":"NAME"},{"location":"commands/ogc-inspect/#synopsis","text":"ogc inspect [OPTIONS]","title":"SYNOPSIS"},{"location":"commands/ogc-inspect/#description","text":"List nodes in your inventory","title":"DESCRIPTION"},{"location":"commands/ogc-inspect/#options","text":"--id TEXT : Inspect node by DB ID --name TEXT : Inspect nodes by name, this can be a substring match --tag TEXT : Inspect nodes by tag --action-id TEXT : If set will only show the action output for a specific action ID","title":"OPTIONS"},{"location":"commands/ogc-launch/","text":"NAME \u00b6 ogc-launch - Launches nodes from a provision specification SYNOPSIS \u00b6 ogc launch [OPTIONS] DESCRIPTION \u00b6 Launches nodes from a provision specification OPTIONS \u00b6 --spec TEXT : <!-- --> --with-deploy / --with-no-deploy : Also performs script deployments (default: Yes)","title":"ogc launch"},{"location":"commands/ogc-launch/#name","text":"ogc-launch - Launches nodes from a provision specification","title":"NAME"},{"location":"commands/ogc-launch/#synopsis","text":"ogc launch [OPTIONS]","title":"SYNOPSIS"},{"location":"commands/ogc-launch/#description","text":"Launches nodes from a provision specification","title":"DESCRIPTION"},{"location":"commands/ogc-launch/#options","text":"--spec TEXT : <!-- --> --with-deploy / --with-no-deploy : Also performs script deployments (default: Yes)","title":"OPTIONS"},{"location":"commands/ogc-log/","text":"NAME \u00b6 ogc-log - Stream log output SYNOPSIS \u00b6 ogc log [OPTIONS] DESCRIPTION \u00b6 Stream log output OPTIONS \u00b6 --debug / --no-debug : Stream debug logging instead","title":"ogc log"},{"location":"commands/ogc-log/#name","text":"ogc-log - Stream log output","title":"NAME"},{"location":"commands/ogc-log/#synopsis","text":"ogc log [OPTIONS]","title":"SYNOPSIS"},{"location":"commands/ogc-log/#description","text":"Stream log output","title":"DESCRIPTION"},{"location":"commands/ogc-log/#options","text":"--debug / --no-debug : Stream debug logging instead","title":"OPTIONS"},{"location":"commands/ogc-ls-key-pairs/","text":"NAME \u00b6 ogc-ls-key-pairs - List keypairs SYNOPSIS \u00b6 ogc ls-key-pairs [OPTIONS] DESCRIPTION \u00b6 List keypairs OPTIONS \u00b6 --filter TEXT : Filter by keypair name --provider TEXT : Provider to query","title":"ogc ls-key-pairs"},{"location":"commands/ogc-ls-key-pairs/#name","text":"ogc-ls-key-pairs - List keypairs","title":"NAME"},{"location":"commands/ogc-ls-key-pairs/#synopsis","text":"ogc ls-key-pairs [OPTIONS]","title":"SYNOPSIS"},{"location":"commands/ogc-ls-key-pairs/#description","text":"List keypairs","title":"DESCRIPTION"},{"location":"commands/ogc-ls-key-pairs/#options","text":"--filter TEXT : Filter by keypair name --provider TEXT : Provider to query","title":"OPTIONS"},{"location":"commands/ogc-ls/","text":"NAME \u00b6 ogc-ls - List nodes in your inventory SYNOPSIS \u00b6 ogc ls [OPTIONS] DESCRIPTION \u00b6 List nodes in your inventory OPTIONS \u00b6 --by-tag TEXT : List nodes by tag --by-name TEXT : List nodes by name, this can be a substring match","title":"ogc ls"},{"location":"commands/ogc-ls/#name","text":"ogc-ls - List nodes in your inventory","title":"NAME"},{"location":"commands/ogc-ls/#synopsis","text":"ogc ls [OPTIONS]","title":"SYNOPSIS"},{"location":"commands/ogc-ls/#description","text":"List nodes in your inventory","title":"DESCRIPTION"},{"location":"commands/ogc-ls/#options","text":"--by-tag TEXT : List nodes by tag --by-name TEXT : List nodes by name, this can be a substring match","title":"OPTIONS"},{"location":"commands/ogc-pull-artifacts/","text":"NAME \u00b6 ogc-pull-artifacts - Download artifacts from node SYNOPSIS \u00b6 ogc pull-artifacts [OPTIONS] NAME DESCRIPTION \u00b6 Download artifacts from node","title":"ogc pull-artifacts"},{"location":"commands/ogc-pull-artifacts/#name","text":"ogc-pull-artifacts - Download artifacts from node","title":"NAME"},{"location":"commands/ogc-pull-artifacts/#synopsis","text":"ogc pull-artifacts [OPTIONS] NAME","title":"SYNOPSIS"},{"location":"commands/ogc-pull-artifacts/#description","text":"Download artifacts from node","title":"DESCRIPTION"},{"location":"commands/ogc-pull-files/","text":"NAME \u00b6 ogc-pull-files - Scp files or directories from node SYNOPSIS \u00b6 ogc pull-files [OPTIONS] NAME DST SRC DESCRIPTION \u00b6 Scp files or directories from node","title":"ogc pull-files"},{"location":"commands/ogc-pull-files/#name","text":"ogc-pull-files - Scp files or directories from node","title":"NAME"},{"location":"commands/ogc-pull-files/#synopsis","text":"ogc pull-files [OPTIONS] NAME DST SRC","title":"SYNOPSIS"},{"location":"commands/ogc-pull-files/#description","text":"Scp files or directories from node","title":"DESCRIPTION"},{"location":"commands/ogc-push-files/","text":"NAME \u00b6 ogc-push-files - Scp files or directories to node SYNOPSIS \u00b6 ogc push-files [OPTIONS] NAME SRC DST DESCRIPTION \u00b6 Scp files or directories to node OPTIONS \u00b6 --exclude TEXT : Exclude files/directories when uploading","title":"ogc push-files"},{"location":"commands/ogc-push-files/#name","text":"ogc-push-files - Scp files or directories to node","title":"NAME"},{"location":"commands/ogc-push-files/#synopsis","text":"ogc push-files [OPTIONS] NAME SRC DST","title":"SYNOPSIS"},{"location":"commands/ogc-push-files/#description","text":"Scp files or directories to node","title":"DESCRIPTION"},{"location":"commands/ogc-push-files/#options","text":"--exclude TEXT : Exclude files/directories when uploading","title":"OPTIONS"},{"location":"commands/ogc-rm-all/","text":"NAME \u00b6 ogc-rm-all - Destroys everything. SYNOPSIS \u00b6 ogc rm-all [OPTIONS] DESCRIPTION \u00b6 Destroys everything. Use with caution. OPTIONS \u00b6 --force / --no-force : Force removal regardless of connectivity --only-db / --no-only-db : Force removal of database records only","title":"ogc rm-all"},{"location":"commands/ogc-rm-all/#name","text":"ogc-rm-all - Destroys everything.","title":"NAME"},{"location":"commands/ogc-rm-all/#synopsis","text":"ogc rm-all [OPTIONS]","title":"SYNOPSIS"},{"location":"commands/ogc-rm-all/#description","text":"Destroys everything. Use with caution.","title":"DESCRIPTION"},{"location":"commands/ogc-rm-all/#options","text":"--force / --no-force : Force removal regardless of connectivity --only-db / --no-only-db : Force removal of database records only","title":"OPTIONS"},{"location":"commands/ogc-rm-key-pairs/","text":"NAME \u00b6 ogc-rm-key-pairs - Remove keypairs SYNOPSIS \u00b6 ogc rm-key-pairs [OPTIONS] DESCRIPTION \u00b6 Remove keypairs OPTIONS \u00b6 --filter TEXT : Filter by keypair name --provider TEXT : Provider to query","title":"ogc rm-key-pairs"},{"location":"commands/ogc-rm-key-pairs/#name","text":"ogc-rm-key-pairs - Remove keypairs","title":"NAME"},{"location":"commands/ogc-rm-key-pairs/#synopsis","text":"ogc rm-key-pairs [OPTIONS]","title":"SYNOPSIS"},{"location":"commands/ogc-rm-key-pairs/#description","text":"Remove keypairs","title":"DESCRIPTION"},{"location":"commands/ogc-rm-key-pairs/#options","text":"--filter TEXT : Filter by keypair name --provider TEXT : Provider to query","title":"OPTIONS"},{"location":"commands/ogc-rm/","text":"NAME \u00b6 ogc-rm - Destroys a node and its associated keys,... SYNOPSIS \u00b6 ogc rm [OPTIONS] DESCRIPTION \u00b6 Destroys a node and its associated keys, storage, etc. OPTIONS \u00b6 --by-name TEXT : Remove node by its Name --force / --no-force : Force removal regardless of connectivity --only-db / --no-only-db : Force removal of database records only","title":"ogc rm"},{"location":"commands/ogc-rm/#name","text":"ogc-rm - Destroys a node and its associated keys,...","title":"NAME"},{"location":"commands/ogc-rm/#synopsis","text":"ogc rm [OPTIONS]","title":"SYNOPSIS"},{"location":"commands/ogc-rm/#description","text":"Destroys a node and its associated keys, storage, etc.","title":"DESCRIPTION"},{"location":"commands/ogc-rm/#options","text":"--by-name TEXT : Remove node by its Name --force / --no-force : Force removal regardless of connectivity --only-db / --no-only-db : Force removal of database records only","title":"OPTIONS"},{"location":"commands/ogc-shell/","text":"NAME \u00b6 ogc-shell - Launches IPython REPL SYNOPSIS \u00b6 ogc shell [OPTIONS] DESCRIPTION \u00b6 Launches IPython REPL","title":"ogc shell"},{"location":"commands/ogc-shell/#name","text":"ogc-shell - Launches IPython REPL","title":"NAME"},{"location":"commands/ogc-shell/#synopsis","text":"ogc shell [OPTIONS]","title":"SYNOPSIS"},{"location":"commands/ogc-shell/#description","text":"Launches IPython REPL","title":"DESCRIPTION"},{"location":"commands/ogc-ssh/","text":"NAME \u00b6 ogc-ssh - Login to a node SYNOPSIS \u00b6 ogc ssh [OPTIONS] DESCRIPTION \u00b6 Login to a node OPTIONS \u00b6 --by-id TEXT : Login to a node by its ID --by-name TEXT : Login to a node by its Name","title":"ogc ssh"},{"location":"commands/ogc-ssh/#name","text":"ogc-ssh - Login to a node","title":"NAME"},{"location":"commands/ogc-ssh/#synopsis","text":"ogc ssh [OPTIONS]","title":"SYNOPSIS"},{"location":"commands/ogc-ssh/#description","text":"Login to a node","title":"DESCRIPTION"},{"location":"commands/ogc-ssh/#options","text":"--by-id TEXT : Login to a node by its ID --by-name TEXT : Login to a node by its Name","title":"OPTIONS"},{"location":"commands/ogc-status/","text":"NAME \u00b6 ogc-status - Get status of deployment SYNOPSIS \u00b6 ogc status [OPTIONS] DESCRIPTION \u00b6 Get status of deployment OPTIONS \u00b6 --reconcile / --no-reconcile : Attempt to fix deployment to match scale --spec TEXT :","title":"ogc status"},{"location":"commands/ogc-status/#name","text":"ogc-status - Get status of deployment","title":"NAME"},{"location":"commands/ogc-status/#synopsis","text":"ogc status [OPTIONS]","title":"SYNOPSIS"},{"location":"commands/ogc-status/#description","text":"Get status of deployment","title":"DESCRIPTION"},{"location":"commands/ogc-status/#options","text":"--reconcile / --no-reconcile : Attempt to fix deployment to match scale --spec TEXT :","title":"OPTIONS"},{"location":"commands/ogc/","text":"NAME \u00b6 ogc - Just a simple provisioner SYNOPSIS \u00b6 ogc [OPTIONS] COMMAND [ARGS]... DESCRIPTION \u00b6 Just a simple provisioner COMMANDS \u00b6 db-migrate Database migrations See ogc-db-migrate(1) for full documentation on the db-migrate command. shell Launches IPython REPL See ogc-shell(1) for full documentation on the shell command. rm Destroys a node and its associated keys,... See ogc-rm(1) for full documentation on the rm command. rm-all Destroys everything. See ogc-rm-all(1) for full documentation on the rm-all command. rm-key-pairs Remove keypairs See ogc-rm-key-pairs(1) for full documentation on the rm-key-pairs command. init Initialize OGC See ogc-init(1) for full documentation on the init command. inspect List nodes in your inventory See ogc-inspect(1) for full documentation on the inspect command. launch Launches nodes from a provision specification See ogc-launch(1) for full documentation on the launch command. ls List nodes in your inventory See ogc-ls(1) for full documentation on the ls command. ls-key-pairs List keypairs See ogc-ls-key-pairs(1) for full documentation on the ls-key-pairs command. ssh Login to a node See ogc-ssh(1) for full documentation on the ssh command. push-files Scp files or directories to node See ogc-push-files(1) for full documentation on the push-files command. pull-files Scp files or directories from node See ogc-pull-files(1) for full documentation on the pull-files command. pull-artifacts Download artifacts from node See ogc-pull-artifacts(1) for full documentation on the pull-artifacts command. exec Execute a command across node(s) See ogc-exec(1) for full documentation on the exec command. exec-scripts (R)Execute a set of scripts See ogc-exec-scripts(1) for full documentation on the exec-scripts command. status Get status of deployment See ogc-status(1) for full documentation on the status command.","title":"ogc"},{"location":"commands/ogc/#name","text":"ogc - Just a simple provisioner","title":"NAME"},{"location":"commands/ogc/#synopsis","text":"ogc [OPTIONS] COMMAND [ARGS]...","title":"SYNOPSIS"},{"location":"commands/ogc/#description","text":"Just a simple provisioner","title":"DESCRIPTION"},{"location":"commands/ogc/#commands","text":"db-migrate Database migrations See ogc-db-migrate(1) for full documentation on the db-migrate command. shell Launches IPython REPL See ogc-shell(1) for full documentation on the shell command. rm Destroys a node and its associated keys,... See ogc-rm(1) for full documentation on the rm command. rm-all Destroys everything. See ogc-rm-all(1) for full documentation on the rm-all command. rm-key-pairs Remove keypairs See ogc-rm-key-pairs(1) for full documentation on the rm-key-pairs command. init Initialize OGC See ogc-init(1) for full documentation on the init command. inspect List nodes in your inventory See ogc-inspect(1) for full documentation on the inspect command. launch Launches nodes from a provision specification See ogc-launch(1) for full documentation on the launch command. ls List nodes in your inventory See ogc-ls(1) for full documentation on the ls command. ls-key-pairs List keypairs See ogc-ls-key-pairs(1) for full documentation on the ls-key-pairs command. ssh Login to a node See ogc-ssh(1) for full documentation on the ssh command. push-files Scp files or directories to node See ogc-push-files(1) for full documentation on the push-files command. pull-files Scp files or directories from node See ogc-pull-files(1) for full documentation on the pull-files command. pull-artifacts Download artifacts from node See ogc-pull-artifacts(1) for full documentation on the pull-artifacts command. exec Execute a command across node(s) See ogc-exec(1) for full documentation on the exec command. exec-scripts (R)Execute a set of scripts See ogc-exec-scripts(1) for full documentation on the exec-scripts command. status Get status of deployment See ogc-status(1) for full documentation on the status command.","title":"COMMANDS"},{"location":"user-guide/defining-layouts/","text":"Defining Layouts \u00b6 Learn the layout specification and how to create your own provisioning layouts. All layouts reside under the layouts key in the provision specification: layouts : elastic-agent-sles : runs-on : sles-15 instance-size : e2-standard-8 username : root scripts : fixtures/ex_deploy_sles provider : google scale : 5 remote-path : /root/ogc include : - .ogc-cache exclude : - .git - .venv artifacts : /root/output/*.xml tags : - elastic-agent-8.1.x - sles-gcp ports : - \"80:80\" - \"443:443\" Each layout has a friendly name associated as seen by elastic-agent-sles . The next section is going to go over each option and describe its meaning. provider Define which cloud the layout will operate in. Currently supported options are aws and google . runs-on Define the base OS image to be deployed on to the nodes. The current supported list of names are: AWS Google ubuntu-latest ubuntu-latest ubuntu-2004 ubuntu-2004 ubuntu-1804 ubuntu-1804 centos-latest sles-latest centos-8 sles-15 sles-latest debian-latest sles-15 debian-10 debian-latest debian-9 debian-11 debian-10 instance-size Define the machine size, this is dependent on which provider is chosen. The instance-size correlates with the instance size naming for each cloud. For example, on AWS you would use instance-size: c5.4xlarge and in Google\u2019s case, instance-size: e2-standard-8 . username The ssh user to use when deploying and accessing the nodes. This is also somewhat dependent on which provider is used. In the case of Google , any username can be given. In the case of AWS , the base machines have a pre-loaded user that must be used: AWS Username ubuntu ubuntu centos ec2-user debian admin scripts The location on your machine where templates/scripts resides. These will be uploaded and executed during the deployment phase. Note See scripting for more information. scale How many nodes of each layout to deploy. This is also referenced during a deployment reconciliation phase. remote-path (optional) If set, any uploads/downloads outside of what\u2019s defined in scripts will be placed in that remote path. include (optional) A list of files/wildcards to include in the upload exclude (optional) A list of files/wildcards to exclude in the upload artifacts (optional) The remote path where script execution output is stored. This is used when pulling artifacts with ogc pull-artifacts and also utilized during node teardown. This will download any artifacts found into artifacts/instance-name/ . tags (optional) Define tags for each layout, allows additional filtering capabilities and deployment options when used with ogc ls and ogc exec ports (optional) Define what ingress ports are available when accessing the node. Variants \u00b6 OGC supports the concept of variants. In OGC\u2019s case, variants are handled by multiple provision spec files and are then merged in a merge-left fashion. What this means is that we can take a base spec file such as: name : ci ssh-keys : public : id_rsa.pub private : id_rsa layouts : elastic-agent-sles : runs-on : sles-15 instance-size : e2-standard-8 username : root scripts : fixtures/ex_deploy_sles provider : google scale : 5 remote-path : /root/ogc include : - .ogc-cache exclude : - .git - .venv artifacts : /root/output/*.xml tags : - elastic-agent-8.1.x - sles-gcp elastic-agent-ubuntu : runs-on : ubuntu-latest instance-size : e2-standard-8 username : root scripts : fixtures/ex_deploy_ubuntu provider : google scale : 5 remote-path : /root/ogc exclude : - .git - .venv artifacts : /root/output/*.xml tags : - elastic-agent-8.1.x - ubuntu-gcp The name of the file doesn\u2019t matter, we\u2019ll call this file base-spec.yml . Now if we need to change certain aspects of this base deploy specification we can define a second YAML file, we\u2019ll call it ubuntu-1804-no-sles.yml . In this example, let\u2019s change the username and runs-on for the ubuntu layout, and let\u2019s also remove the sles layout: layouts : elastic-agent-sles : {} elastic-agent-ubuntu : runs-on : ubuntu-1804 username : ubuntu The merging of the specifications will remove any keys that exist if the value of the key is {} (signaling an empty stanza). The remaining keys that match up with the original spec will then be overridden and the rest of the specification is left untouched. Adding new layouts is just a matter of defining another section under layouts in the additional spec files passed to OGC.","title":"Defining Layouts"},{"location":"user-guide/defining-layouts/#defining-layouts","text":"Learn the layout specification and how to create your own provisioning layouts. All layouts reside under the layouts key in the provision specification: layouts : elastic-agent-sles : runs-on : sles-15 instance-size : e2-standard-8 username : root scripts : fixtures/ex_deploy_sles provider : google scale : 5 remote-path : /root/ogc include : - .ogc-cache exclude : - .git - .venv artifacts : /root/output/*.xml tags : - elastic-agent-8.1.x - sles-gcp ports : - \"80:80\" - \"443:443\" Each layout has a friendly name associated as seen by elastic-agent-sles . The next section is going to go over each option and describe its meaning. provider Define which cloud the layout will operate in. Currently supported options are aws and google . runs-on Define the base OS image to be deployed on to the nodes. The current supported list of names are: AWS Google ubuntu-latest ubuntu-latest ubuntu-2004 ubuntu-2004 ubuntu-1804 ubuntu-1804 centos-latest sles-latest centos-8 sles-15 sles-latest debian-latest sles-15 debian-10 debian-latest debian-9 debian-11 debian-10 instance-size Define the machine size, this is dependent on which provider is chosen. The instance-size correlates with the instance size naming for each cloud. For example, on AWS you would use instance-size: c5.4xlarge and in Google\u2019s case, instance-size: e2-standard-8 . username The ssh user to use when deploying and accessing the nodes. This is also somewhat dependent on which provider is used. In the case of Google , any username can be given. In the case of AWS , the base machines have a pre-loaded user that must be used: AWS Username ubuntu ubuntu centos ec2-user debian admin scripts The location on your machine where templates/scripts resides. These will be uploaded and executed during the deployment phase. Note See scripting for more information. scale How many nodes of each layout to deploy. This is also referenced during a deployment reconciliation phase. remote-path (optional) If set, any uploads/downloads outside of what\u2019s defined in scripts will be placed in that remote path. include (optional) A list of files/wildcards to include in the upload exclude (optional) A list of files/wildcards to exclude in the upload artifacts (optional) The remote path where script execution output is stored. This is used when pulling artifacts with ogc pull-artifacts and also utilized during node teardown. This will download any artifacts found into artifacts/instance-name/ . tags (optional) Define tags for each layout, allows additional filtering capabilities and deployment options when used with ogc ls and ogc exec ports (optional) Define what ingress ports are available when accessing the node.","title":"Defining Layouts"},{"location":"user-guide/defining-layouts/#variants","text":"OGC supports the concept of variants. In OGC\u2019s case, variants are handled by multiple provision spec files and are then merged in a merge-left fashion. What this means is that we can take a base spec file such as: name : ci ssh-keys : public : id_rsa.pub private : id_rsa layouts : elastic-agent-sles : runs-on : sles-15 instance-size : e2-standard-8 username : root scripts : fixtures/ex_deploy_sles provider : google scale : 5 remote-path : /root/ogc include : - .ogc-cache exclude : - .git - .venv artifacts : /root/output/*.xml tags : - elastic-agent-8.1.x - sles-gcp elastic-agent-ubuntu : runs-on : ubuntu-latest instance-size : e2-standard-8 username : root scripts : fixtures/ex_deploy_ubuntu provider : google scale : 5 remote-path : /root/ogc exclude : - .git - .venv artifacts : /root/output/*.xml tags : - elastic-agent-8.1.x - ubuntu-gcp The name of the file doesn\u2019t matter, we\u2019ll call this file base-spec.yml . Now if we need to change certain aspects of this base deploy specification we can define a second YAML file, we\u2019ll call it ubuntu-1804-no-sles.yml . In this example, let\u2019s change the username and runs-on for the ubuntu layout, and let\u2019s also remove the sles layout: layouts : elastic-agent-sles : {} elastic-agent-ubuntu : runs-on : ubuntu-1804 username : ubuntu The merging of the specifications will remove any keys that exist if the value of the key is {} (signaling an empty stanza). The remaining keys that match up with the original spec will then be overridden and the rest of the specification is left untouched. Adding new layouts is just a matter of defining another section under layouts in the additional spec files passed to OGC.","title":"Variants"},{"location":"user-guide/managing-nodes/","text":"Managing a Deployment \u00b6 Learn how to list, inspect, access and debug your node deployments. Listing Nodes \u00b6 To list nodes in your deployment, run the following: $ ogc ls Which gives a table output of current node deployments: \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2503 10 Nodes \u2503 Name \u2503 Status \u2503 Connection \u2503 Tags \u2503 Actions \u2503 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502 20 \u2502 ogc-87ba30fc-elastic-agent-sles \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@34.123.103.9 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 sles-gcp \u2502 \u2502 \u2502 34 \u2502 ogc-b3befadc-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@35.184.43.81 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 35 \u2502 ogc-d54a5848-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@34.121.133.188 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 36 \u2502 ogc-cbb9d5bc-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@34.67.108.205 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 21 \u2502 ogc-51b971ad-elastic-agent-sles \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@35.239.181.14 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 sles-gcp \u2502 \u2502 \u2502 22 \u2502 ogc-c4f812b7-elastic-agent-sles \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@35.184.34.2 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 sles-gcp \u2502 \u2502 \u2502 23 \u2502 ogc-7c8cb271-elastic-agent-sles \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@34.72.237.134 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 sles-gcp \u2502 \u2502 \u2502 24 \u2502 ogc-d4467204-elastic-agent-sles \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@34.132.30.47 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 sles-gcp \u2502 \u2502 \u2502 37 \u2502 ogc-92f1c5ec-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@104.197.37.199 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 38 \u2502 ogc-d7cd61a7-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@35.225.239.252 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 You can further drill down with a couple of options: To filter by-tag run: $ ogc ls --by-tag ubuntu-gcp \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2503 5 Nodes \u2503 Name \u2503 Status \u2503 Connection \u2503 Tags \u2503 Actions \u2503 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502 34 \u2502 ogc-b3befadc-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@35.184.43.81 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 35 \u2502 ogc-d54a5848-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@34.121.133.188 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 36 \u2502 ogc-cbb9d5bc-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@34.67.108.205 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 37 \u2502 ogc-92f1c5ec-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@104.197.37.199 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 38 \u2502 ogc-d7cd61a7-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@35.225.239.252 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Accessing nodes \u00b6 OGC provides a helper command for easily accessing any of the nodes in your deployment. To login to one of the above nodes ogc-d7cd61a7-elastic-agent-ubuntu run: $ ogc ssh --by-name ogc-d7cd61a7-elastic-agent-ubuntu ... ssh output ... root@ogc-d7cd61a7-elastic-agent-ubuntu:~# Alternatively, use the ID : $ ogc ssh --by-id 38 Executing commands \u00b6 Running arbitrary commands can be accomplished with: $ ogc exec --by-name ogc-d7cd61a7-elastic-agent-ubuntu 'ls -l /' Or if tags are defined, run a command across a set of machines: $ ogc exec --by-tag ubuntu-gcp 'touch this_is_an_ubuntu_machine.txt' Executing a scripts directory \u00b6 In addition to running arbitrary commands, OGC can also execute a directory of templates/scripts: $ ogc exec-scripts --by-name ogc-d7cd61a7-elastic-agent-ubuntu fixtures/ex_deploy_ubuntu Or if tags are defined, run across a set of machines: $ ogc exec-scripts --by-tag ubuntu-gcp fixtures/ex_deploy_ubuntu This can be useful to re-run a deployment or add new functionality/one-offs to a node without disturbing the original layout specifications. Access to the database and all templating is available as well. Downloading files \u00b6 There are 2 ways to download files, the first is to use ogc pull-files , this gives you the ability to download any arbitrary files: $ ogc pull-files ogc-d7cd61a7-elastic-agent-ubuntu im_on_a_computer.txt im_downloaded_computer.txt $ stat im_downloaded_computer.txt 16777221 24809112 -rw-r--r-- 1 adam staff 0 0 \"Mar 24 11:56:24 2022\" \"Mar 24 11:55:16 2022\" \"Mar 24 11:56:24 2022\" \"Mar 24 11:55:16 2022\" 4096 0 0 im_downloaded_computer.txt Another way is if the artifacts key is defined in a layout. To grab files defined by that artifacts option run the following: $ ogc pull-artifacts ogc-d7cd61a7-elastic-agent-ubuntu By default, artifacts are stored in $(pwd)/artifacts/ogc-d7cd61a7-elastic-agent-ubuntu tree artifacts/ogc-d7cd61a7-elastic-agent-ubuntu/ artifacts/ogc-d7cd61a7-elastic-agent-ubuntu/ \u2514\u2500\u2500 test.xml 0 directories, 1 file Uploading files \u00b6 OGC provides a simple way to upload arbitrary files to a node: $ ogc push-files ogc-d7cd61a7-elastic-agent-ubuntu im_downloaded_computer.txt dl.txt Optionally, if --exclude is provided, uploading files will ignore any wildcards matched. Passing multiple --exclude is supported and will be added to the list of excludes during upload. Useful if uploading directories and want to ignore things like .git and .venv . Inspecting nodes \u00b6 Each action performed on a node is tracked. This allows you to quickly investigate why scripts failed. To inspect a node and see action results run: $ ogc inspect --id 38 This will return the following output: Deploy Details: ogc-d7cd61a7-elastic-agent-ubuntu [3] Successful Actions: (id: 90) Out: 2022-03-24 12:37:08.657289 '/usr/local/bin/pacman' -> '/usr/local/bin/pacapt' Reading package lists... Building dependency tree... Reading state information... nano is already the newest version (2.9.3-2). nano set to manually installed. The following package was automatically installed and is no longer required: libnuma1 Use 'apt autoremove' to remove it. 0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded. If multiple actions exist, further drill down into the action you want ( seen here \u201c(id: 90) Out: 2022-03-24 12:37:08.\u201d in our example ): $ ogc inspect --id 38 --action-id 90 Syncing a deployment \u00b6 In some cases nodes will fail to deploy or you remembered you needed more than 5 nodes or maybe you need less nodes than what the original scale was set. In all these cases, OGC provides a way to keep the deployment in sync with the layouts. To get an idea of the health of the deployment, run: $ ogc status The output returned will be a table displaying what\u2019s deployed, the scale, and if there are any remaining nodes left: Deployment Status: Healthy \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2503 Name \u2503 Deployed \u2503 Scale \u2503 Remaining \u2503 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502 elastic-agent-sles \u2502 5 \u2502 5 \u2502 0 \u2502 \u2502 elastic-agent-ubuntu \u2502 5 \u2502 5 \u2502 0 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 In cases where you want to add more nodes, update your layout and increase the scale option, in this case we want to add 10 more nodes to our elastic-agent-sles layout: Deployment Status: Degraded \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2503 Name \u2503 Deployed \u2503 Scale \u2503 Remaining \u2503 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502 elastic-agent-sles \u2502 5 \u2502 15 \u2502 10 \u2502 \u2502 elastic-agent-ubuntu \u2502 5 \u2502 5 \u2502 0 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Or another case where we need to reduce the number of nodes from 5 to 3: Deployment Status: Degraded \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2503 Name \u2503 Deployed \u2503 Scale \u2503 Remaining \u2503 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502 elastic-agent-sles \u2502 5 \u2502 3 \u2502 -2 \u2502 \u2502 elastic-agent-ubuntu \u2502 5 \u2502 3 \u2502 -2 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 To perform the sync, run the following: $ ogc status --reconcile And the output will show OGC destroying 2 nodes from each layout: 2022-03-24 at 11:52:37 | INFO Reconciling: [elastic-agent-sles, elastic-agent-ubuntu] 2022-03-24 at 11:52:37 | INFO Destroying: ogc-87ba30fc-elastic-agent-sles 2022-03-24 at 11:52:37 | INFO Destroying: ogc-51b971ad-elastic-agent-sles 2022-03-24 at 11:52:37 | INFO Destroying: ogc-b3befadc-elastic-agent-ubuntu 2022-03-24 at 11:52:37 | INFO Destroying: ogc-d54a5848-elastic-agent-ubuntu Destroying nodes \u00b6 OGC allows destroying of individual or a full blown cleanup. To remove a single node we run: $ ogc rm ogc-d7cd61a7-elastic-agent-ubuntu --force Or if we wanted to do a full teardown, run: $ ogc rm-all --force","title":"Managing a deployment"},{"location":"user-guide/managing-nodes/#managing-a-deployment","text":"Learn how to list, inspect, access and debug your node deployments.","title":"Managing a Deployment"},{"location":"user-guide/managing-nodes/#listing-nodes","text":"To list nodes in your deployment, run the following: $ ogc ls Which gives a table output of current node deployments: \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2503 10 Nodes \u2503 Name \u2503 Status \u2503 Connection \u2503 Tags \u2503 Actions \u2503 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502 20 \u2502 ogc-87ba30fc-elastic-agent-sles \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@34.123.103.9 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 sles-gcp \u2502 \u2502 \u2502 34 \u2502 ogc-b3befadc-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@35.184.43.81 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 35 \u2502 ogc-d54a5848-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@34.121.133.188 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 36 \u2502 ogc-cbb9d5bc-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@34.67.108.205 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 21 \u2502 ogc-51b971ad-elastic-agent-sles \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@35.239.181.14 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 sles-gcp \u2502 \u2502 \u2502 22 \u2502 ogc-c4f812b7-elastic-agent-sles \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@35.184.34.2 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 sles-gcp \u2502 \u2502 \u2502 23 \u2502 ogc-7c8cb271-elastic-agent-sles \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@34.72.237.134 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 sles-gcp \u2502 \u2502 \u2502 24 \u2502 ogc-d4467204-elastic-agent-sles \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@34.132.30.47 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 sles-gcp \u2502 \u2502 \u2502 37 \u2502 ogc-92f1c5ec-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@104.197.37.199 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 38 \u2502 ogc-d7cd61a7-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@35.225.239.252 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 You can further drill down with a couple of options: To filter by-tag run: $ ogc ls --by-tag ubuntu-gcp \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2503 5 Nodes \u2503 Name \u2503 Status \u2503 Connection \u2503 Tags \u2503 Actions \u2503 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502 34 \u2502 ogc-b3befadc-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@35.184.43.81 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 35 \u2502 ogc-d54a5848-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@34.121.133.188 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 36 \u2502 ogc-cbb9d5bc-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@34.67.108.205 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 37 \u2502 ogc-92f1c5ec-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@104.197.37.199 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 38 \u2502 ogc-d7cd61a7-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@35.225.239.252 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Listing Nodes"},{"location":"user-guide/managing-nodes/#accessing-nodes","text":"OGC provides a helper command for easily accessing any of the nodes in your deployment. To login to one of the above nodes ogc-d7cd61a7-elastic-agent-ubuntu run: $ ogc ssh --by-name ogc-d7cd61a7-elastic-agent-ubuntu ... ssh output ... root@ogc-d7cd61a7-elastic-agent-ubuntu:~# Alternatively, use the ID : $ ogc ssh --by-id 38","title":"Accessing nodes"},{"location":"user-guide/managing-nodes/#executing-commands","text":"Running arbitrary commands can be accomplished with: $ ogc exec --by-name ogc-d7cd61a7-elastic-agent-ubuntu 'ls -l /' Or if tags are defined, run a command across a set of machines: $ ogc exec --by-tag ubuntu-gcp 'touch this_is_an_ubuntu_machine.txt'","title":"Executing commands"},{"location":"user-guide/managing-nodes/#executing-a-scripts-directory","text":"In addition to running arbitrary commands, OGC can also execute a directory of templates/scripts: $ ogc exec-scripts --by-name ogc-d7cd61a7-elastic-agent-ubuntu fixtures/ex_deploy_ubuntu Or if tags are defined, run across a set of machines: $ ogc exec-scripts --by-tag ubuntu-gcp fixtures/ex_deploy_ubuntu This can be useful to re-run a deployment or add new functionality/one-offs to a node without disturbing the original layout specifications. Access to the database and all templating is available as well.","title":"Executing a scripts directory"},{"location":"user-guide/managing-nodes/#downloading-files","text":"There are 2 ways to download files, the first is to use ogc pull-files , this gives you the ability to download any arbitrary files: $ ogc pull-files ogc-d7cd61a7-elastic-agent-ubuntu im_on_a_computer.txt im_downloaded_computer.txt $ stat im_downloaded_computer.txt 16777221 24809112 -rw-r--r-- 1 adam staff 0 0 \"Mar 24 11:56:24 2022\" \"Mar 24 11:55:16 2022\" \"Mar 24 11:56:24 2022\" \"Mar 24 11:55:16 2022\" 4096 0 0 im_downloaded_computer.txt Another way is if the artifacts key is defined in a layout. To grab files defined by that artifacts option run the following: $ ogc pull-artifacts ogc-d7cd61a7-elastic-agent-ubuntu By default, artifacts are stored in $(pwd)/artifacts/ogc-d7cd61a7-elastic-agent-ubuntu tree artifacts/ogc-d7cd61a7-elastic-agent-ubuntu/ artifacts/ogc-d7cd61a7-elastic-agent-ubuntu/ \u2514\u2500\u2500 test.xml 0 directories, 1 file","title":"Downloading files"},{"location":"user-guide/managing-nodes/#uploading-files","text":"OGC provides a simple way to upload arbitrary files to a node: $ ogc push-files ogc-d7cd61a7-elastic-agent-ubuntu im_downloaded_computer.txt dl.txt Optionally, if --exclude is provided, uploading files will ignore any wildcards matched. Passing multiple --exclude is supported and will be added to the list of excludes during upload. Useful if uploading directories and want to ignore things like .git and .venv .","title":"Uploading files"},{"location":"user-guide/managing-nodes/#inspecting-nodes","text":"Each action performed on a node is tracked. This allows you to quickly investigate why scripts failed. To inspect a node and see action results run: $ ogc inspect --id 38 This will return the following output: Deploy Details: ogc-d7cd61a7-elastic-agent-ubuntu [3] Successful Actions: (id: 90) Out: 2022-03-24 12:37:08.657289 '/usr/local/bin/pacman' -> '/usr/local/bin/pacapt' Reading package lists... Building dependency tree... Reading state information... nano is already the newest version (2.9.3-2). nano set to manually installed. The following package was automatically installed and is no longer required: libnuma1 Use 'apt autoremove' to remove it. 0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded. If multiple actions exist, further drill down into the action you want ( seen here \u201c(id: 90) Out: 2022-03-24 12:37:08.\u201d in our example ): $ ogc inspect --id 38 --action-id 90","title":"Inspecting nodes"},{"location":"user-guide/managing-nodes/#syncing-a-deployment","text":"In some cases nodes will fail to deploy or you remembered you needed more than 5 nodes or maybe you need less nodes than what the original scale was set. In all these cases, OGC provides a way to keep the deployment in sync with the layouts. To get an idea of the health of the deployment, run: $ ogc status The output returned will be a table displaying what\u2019s deployed, the scale, and if there are any remaining nodes left: Deployment Status: Healthy \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2503 Name \u2503 Deployed \u2503 Scale \u2503 Remaining \u2503 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502 elastic-agent-sles \u2502 5 \u2502 5 \u2502 0 \u2502 \u2502 elastic-agent-ubuntu \u2502 5 \u2502 5 \u2502 0 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 In cases where you want to add more nodes, update your layout and increase the scale option, in this case we want to add 10 more nodes to our elastic-agent-sles layout: Deployment Status: Degraded \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2503 Name \u2503 Deployed \u2503 Scale \u2503 Remaining \u2503 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502 elastic-agent-sles \u2502 5 \u2502 15 \u2502 10 \u2502 \u2502 elastic-agent-ubuntu \u2502 5 \u2502 5 \u2502 0 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Or another case where we need to reduce the number of nodes from 5 to 3: Deployment Status: Degraded \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2503 Name \u2503 Deployed \u2503 Scale \u2503 Remaining \u2503 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502 elastic-agent-sles \u2502 5 \u2502 3 \u2502 -2 \u2502 \u2502 elastic-agent-ubuntu \u2502 5 \u2502 3 \u2502 -2 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 To perform the sync, run the following: $ ogc status --reconcile And the output will show OGC destroying 2 nodes from each layout: 2022-03-24 at 11:52:37 | INFO Reconciling: [elastic-agent-sles, elastic-agent-ubuntu] 2022-03-24 at 11:52:37 | INFO Destroying: ogc-87ba30fc-elastic-agent-sles 2022-03-24 at 11:52:37 | INFO Destroying: ogc-51b971ad-elastic-agent-sles 2022-03-24 at 11:52:37 | INFO Destroying: ogc-b3befadc-elastic-agent-ubuntu 2022-03-24 at 11:52:37 | INFO Destroying: ogc-d54a5848-elastic-agent-ubuntu","title":"Syncing a deployment"},{"location":"user-guide/managing-nodes/#destroying-nodes","text":"OGC allows destroying of individual or a full blown cleanup. To remove a single node we run: $ ogc rm ogc-d7cd61a7-elastic-agent-ubuntu --force Or if we wanted to do a full teardown, run: $ ogc rm-all --force","title":"Destroying nodes"},{"location":"user-guide/providers/","text":"Providers \u00b6 In order to access a cloud provider, there are certain environment variables that need to be exposed for each. Each environment variable should be defined in .env file so it will be automatically loaded when running OGC. AWS \u00b6 AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY AWS_REGION Google \u00b6 GOOGLE_APPLICATION_CREDENTIALS GOOGLE_APPLICATION_SERVICE_ACCOUNT GOOGLE_PROJECT GOOGLE_DATACENTER","title":"Providers"},{"location":"user-guide/providers/#providers","text":"In order to access a cloud provider, there are certain environment variables that need to be exposed for each. Each environment variable should be defined in .env file so it will be automatically loaded when running OGC.","title":"Providers"},{"location":"user-guide/providers/#aws","text":"AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY AWS_REGION","title":"AWS"},{"location":"user-guide/providers/#google","text":"GOOGLE_APPLICATION_CREDENTIALS GOOGLE_APPLICATION_SERVICE_ACCOUNT GOOGLE_PROJECT GOOGLE_DATACENTER","title":"Google"},{"location":"user-guide/scripting/","text":"Scripting \u00b6 All deployments have the ability to execute scripts once a node becomes available. Before starting \u00b6 A couple of things to keep in mind: All scripts are executed in order based on the filenames. It is recommended to create scripts with a numbered prefix, for example: - scripts/ - 01-install-deps - 02-configure-services There is a special reserved filename teardown , if this file exists it will only be executed during a removal of a node. This is useful for any cleanup actions that may need to be run, such as removing test users, un-enrolling from a service, etc. Writing scripts \u00b6 Scripts can be written in any language, it is up to you to configure the nodes so that any runtimes and library dependencies are met on the target node for your script to execute in. One way to accomplish this is to create 01-setup-env bash script: #!/bin/bash echo \"Installing python3 on ubuntu\" sudo apt-get update sudo apt-get install -qyf python3 sudo pip install sh Then in subsequent scripts, using python3 is available. For example, in file 02-run-cmd-in-python : #!/usr/bin/env python3 import sh sh . ls ( '/' ) sh . cp ( '-a' , 'mydir' , 'anotherdir' ) Templating \u00b6 OGC provides some additional capabilities through templating. Under the hood python-mako is used for the parsing. With templating, you have the ability to query the underlying database to gather node information. Because mako supports the importing of python modules and our OGC environment is already exposed, we can access our db module and use some helper methods. #!/bin/bash <%namespace name = \"db\" module = \"ogc.db\" /> echo \"\" % for node in db.by_tag ( 'sles' ) : echo \"[ID: ${ node .id } ] Name: ${ node .instance_name } || Connection: ${ node .username } @ ${ node .public_ip } || Provider: ${ node .provider } \" % endfor echo \"\" The runtime environment is also available within the template context. In one example, we can export the following into our .env file and reference those in the templates: OGC_ELASTIC_AGENT_VERSION OGC_ELASTIC_AGENT_SHA OGC_ELASTIC_AGENT_VERSION OGC_FLEET_URL OGC_FLEET_ENROLLMENT_TOKEN See the below example for downloading elastic-agent and enrolling it into a fleet server. The variable exposed to all templates for accessing the environment variables is env #!/bin/bash <%namespace name = \"utils\" file = \"/functions.mako\" /> <% url = \"https://staging.elastic.co/%s-%s/downloads/beats/elastic-agent/elastic-agent-%s-linux-x86_64.tar.gz\" % ( env [ 'OGC_ELASTIC_AGENT_VERSION' ] , env [ 'OGC_ELASTIC_AGENT_SHA' ] , env [ 'OGC_ELASTIC_AGENT_VERSION' ]) %> ${ utils .setup_env() } ${ utils .install_pkgs([ 'nano' ]) } ${ utils .download(url, 'elastic-agent.tar.gz' ) } ${ utils .extract( 'elastic-agent.tar.gz' ) } mv elastic-agent- ${ env [ 'OGC_ELASTIC_AGENT_VERSION' ] } -linux-x86_64 elastic-agent cd elastic-agent && ./elastic-agent install -f --url = ${ env [ 'OGC_FLEET_URL' ] } --enrollment-token = ${ env [ 'OGC_FLEET_ENROLLMENT_TOKEN' ] } Reusable helpers \u00b6 In the above example we reference a file called /functions.mako this is just another template file that sits just outside of our defined scripts , for example, if our scripts is defined to be in scripts/my_ubuntu_deploy then this functions.mako will live at scripts/functions.mako . This is good practice as you may have multiple layouts with different script directories for each and would like to store common functionality in a single place. Defining helper functions is straight forward, lets look at functions.mako for an example: ## Helper template functions downloading/extracting files <%def name = \"setup_env()\" > if ! test -f \"/usr/local/bin/pacapt\" ; then wget -O /usr/local/bin/pacapt https://github.com/icy/pacapt/raw/ng/pacapt chmod 755 /usr/local/bin/pacapt ln -sv /usr/local/bin/pacapt /usr/local/bin/pacman || true fi </%def> <%def name = \"install_pkgs(pkgs)\" > % for pkg in pkgs: pacapt install --noconfirm ${ pkg } % endfor </%def> <%def name = \"download(url, src_file)\" > wget -O ${ src_file } ${ url } </%def> <%def name = \"extract(src, dst=None)\" > % if dst: mkdir -p ${ dst } tar -xvf ${ src } -C ${ dst } % else : tar -xvf ${ src } % endif </%def> Each %def section defines a function block that when called with any necessary arguments will output that data into the scripts with all necessary translations handled. You can see the usage of these functions in the previous example for installing elastic-agent. It is worth the time to visit Mako\u2019s website and learn about its feature set, particularly namespaces and defs and blocks .","title":"Scripting"},{"location":"user-guide/scripting/#scripting","text":"All deployments have the ability to execute scripts once a node becomes available.","title":"Scripting"},{"location":"user-guide/scripting/#before-starting","text":"A couple of things to keep in mind: All scripts are executed in order based on the filenames. It is recommended to create scripts with a numbered prefix, for example: - scripts/ - 01-install-deps - 02-configure-services There is a special reserved filename teardown , if this file exists it will only be executed during a removal of a node. This is useful for any cleanup actions that may need to be run, such as removing test users, un-enrolling from a service, etc.","title":"Before starting"},{"location":"user-guide/scripting/#writing-scripts","text":"Scripts can be written in any language, it is up to you to configure the nodes so that any runtimes and library dependencies are met on the target node for your script to execute in. One way to accomplish this is to create 01-setup-env bash script: #!/bin/bash echo \"Installing python3 on ubuntu\" sudo apt-get update sudo apt-get install -qyf python3 sudo pip install sh Then in subsequent scripts, using python3 is available. For example, in file 02-run-cmd-in-python : #!/usr/bin/env python3 import sh sh . ls ( '/' ) sh . cp ( '-a' , 'mydir' , 'anotherdir' )","title":"Writing scripts"},{"location":"user-guide/scripting/#templating","text":"OGC provides some additional capabilities through templating. Under the hood python-mako is used for the parsing. With templating, you have the ability to query the underlying database to gather node information. Because mako supports the importing of python modules and our OGC environment is already exposed, we can access our db module and use some helper methods. #!/bin/bash <%namespace name = \"db\" module = \"ogc.db\" /> echo \"\" % for node in db.by_tag ( 'sles' ) : echo \"[ID: ${ node .id } ] Name: ${ node .instance_name } || Connection: ${ node .username } @ ${ node .public_ip } || Provider: ${ node .provider } \" % endfor echo \"\" The runtime environment is also available within the template context. In one example, we can export the following into our .env file and reference those in the templates: OGC_ELASTIC_AGENT_VERSION OGC_ELASTIC_AGENT_SHA OGC_ELASTIC_AGENT_VERSION OGC_FLEET_URL OGC_FLEET_ENROLLMENT_TOKEN See the below example for downloading elastic-agent and enrolling it into a fleet server. The variable exposed to all templates for accessing the environment variables is env #!/bin/bash <%namespace name = \"utils\" file = \"/functions.mako\" /> <% url = \"https://staging.elastic.co/%s-%s/downloads/beats/elastic-agent/elastic-agent-%s-linux-x86_64.tar.gz\" % ( env [ 'OGC_ELASTIC_AGENT_VERSION' ] , env [ 'OGC_ELASTIC_AGENT_SHA' ] , env [ 'OGC_ELASTIC_AGENT_VERSION' ]) %> ${ utils .setup_env() } ${ utils .install_pkgs([ 'nano' ]) } ${ utils .download(url, 'elastic-agent.tar.gz' ) } ${ utils .extract( 'elastic-agent.tar.gz' ) } mv elastic-agent- ${ env [ 'OGC_ELASTIC_AGENT_VERSION' ] } -linux-x86_64 elastic-agent cd elastic-agent && ./elastic-agent install -f --url = ${ env [ 'OGC_FLEET_URL' ] } --enrollment-token = ${ env [ 'OGC_FLEET_ENROLLMENT_TOKEN' ] }","title":"Templating"},{"location":"user-guide/scripting/#reusable-helpers","text":"In the above example we reference a file called /functions.mako this is just another template file that sits just outside of our defined scripts , for example, if our scripts is defined to be in scripts/my_ubuntu_deploy then this functions.mako will live at scripts/functions.mako . This is good practice as you may have multiple layouts with different script directories for each and would like to store common functionality in a single place. Defining helper functions is straight forward, lets look at functions.mako for an example: ## Helper template functions downloading/extracting files <%def name = \"setup_env()\" > if ! test -f \"/usr/local/bin/pacapt\" ; then wget -O /usr/local/bin/pacapt https://github.com/icy/pacapt/raw/ng/pacapt chmod 755 /usr/local/bin/pacapt ln -sv /usr/local/bin/pacapt /usr/local/bin/pacman || true fi </%def> <%def name = \"install_pkgs(pkgs)\" > % for pkg in pkgs: pacapt install --noconfirm ${ pkg } % endfor </%def> <%def name = \"download(url, src_file)\" > wget -O ${ src_file } ${ url } </%def> <%def name = \"extract(src, dst=None)\" > % if dst: mkdir -p ${ dst } tar -xvf ${ src } -C ${ dst } % else : tar -xvf ${ src } % endif </%def> Each %def section defines a function block that when called with any necessary arguments will output that data into the scripts with all necessary translations handled. You can see the usage of these functions in the previous example for installing elastic-agent. It is worth the time to visit Mako\u2019s website and learn about its feature set, particularly namespaces and defs and blocks .","title":"Reusable helpers"}]}