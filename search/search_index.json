{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"OGC \u00b6 ogc - provisioning, that\u2019s it. Getting Started \u00b6 Welcome to the getting started guide! This should be a quick introduction to get up and running with OGC. More information on customizing and extending OGC can be found in the user documentation. Setup \u00b6 OGC requires Redis and Postgres to function. The easiest way to fulfill these requirements is with docker-compose : version : \"3.9\" services : redis : image : \"redis:6.2-alpine\" restart : always volumes : - \"redis:/data\" ports : - '6379:6379' postgres : image : postgres:11 environment : - POSTGRES_DB=ogc - POSTGRES_USER=postgres - POSTGRES_PASSWORD=postgres healthcheck : test : [ \"CMD\" , \"pg_isready\" , \"-U\" , \"postgres\" ] retries : 300 interval : 1s ports : - '5432:5432' volumes : redis : {} Bring up the services $ docker-compose up Next , is installation of OGC. We use Poetry : $ pip install poetry == 1 .1.12 $ poetry install Or install from pypi : $ pip install ogc Provider Setup \u00b6 OGC currently supports AWS and GCP out of the box (more added soon). In order for OGC to connect and deploy to these clouds a few environment variables are needed. Create a .env file in the top level directory where ogc is to be run: AWS_ACCESS_KEY_ID=\"\" AWS_SECRET_ACCESS_KEY=\"\" AWS_REGION=\"us-east-2\" GOOGLE_APPLICATION_CREDENTIALS=\"svc.json\" GOOGLE_APPLICATION_SERVICE_ACCOUNT=\"..@...iam.gserviceaccount.com\" GOOGLE_PROJECT=\"example-project\" GOOGLE_DATACENTER=\"us-central1-a\" Define Provisioning \u00b6 Once setup is complete, a provision specification is needed. This defines ssh-keys and one or more layouts to be provisioned. Create a file ogc.yml and place in the top level directory where ogc is run: name : ci # SSH Keys must be passwordless ssh-keys : public : ~/.ssh/id_rsa_libcloud.pub private : ~/.ssh/id_rsa_libcloud layouts : elastic-agent-sles : runs-on : sles-15 instance-size : e2-standard-8 username : root scripts : fixtures/ex_deploy_sles provider : google scale : 5 remote-path : /root/ogc include : - .ogc-cache exclude : - .git - .venv artifacts : /root/output/*.xml tags : - elastic-agent-8.1.x - sles-gcp This specification tells OGC to deploy 5 nodes running on Google\u2019s e2-standard-8 with SUSE 15 OS. The scripts section tells OGC where the template files/scripts are located that need to be uploaded to each node during the deployment phase. Provision and Deploy \u00b6 OGC uses a client/server architecture to better handle scaling and concurrency needs. A celery server needs to be available prior launching nodes: $ ogc server Note : An alternative is to run this process in a separate docker container. Once the specification is set, environment variables configured and celery is running, execute a deployment in a new terminal: $ ogc launch Note : If the file is something other than ogc.yml append the --spec option to the launch command: $ ogc launch --spec my-custom-provision.yml Next steps \u00b6 Learn how to manage your deployments in our User Guide - Managing a deployment","title":"Getting Started"},{"location":"#ogc","text":"ogc - provisioning, that\u2019s it.","title":"OGC"},{"location":"#getting-started","text":"Welcome to the getting started guide! This should be a quick introduction to get up and running with OGC. More information on customizing and extending OGC can be found in the user documentation.","title":"Getting Started"},{"location":"#setup","text":"OGC requires Redis and Postgres to function. The easiest way to fulfill these requirements is with docker-compose : version : \"3.9\" services : redis : image : \"redis:6.2-alpine\" restart : always volumes : - \"redis:/data\" ports : - '6379:6379' postgres : image : postgres:11 environment : - POSTGRES_DB=ogc - POSTGRES_USER=postgres - POSTGRES_PASSWORD=postgres healthcheck : test : [ \"CMD\" , \"pg_isready\" , \"-U\" , \"postgres\" ] retries : 300 interval : 1s ports : - '5432:5432' volumes : redis : {} Bring up the services $ docker-compose up Next , is installation of OGC. We use Poetry : $ pip install poetry == 1 .1.12 $ poetry install Or install from pypi : $ pip install ogc","title":"Setup"},{"location":"#provider-setup","text":"OGC currently supports AWS and GCP out of the box (more added soon). In order for OGC to connect and deploy to these clouds a few environment variables are needed. Create a .env file in the top level directory where ogc is to be run: AWS_ACCESS_KEY_ID=\"\" AWS_SECRET_ACCESS_KEY=\"\" AWS_REGION=\"us-east-2\" GOOGLE_APPLICATION_CREDENTIALS=\"svc.json\" GOOGLE_APPLICATION_SERVICE_ACCOUNT=\"..@...iam.gserviceaccount.com\" GOOGLE_PROJECT=\"example-project\" GOOGLE_DATACENTER=\"us-central1-a\"","title":"Provider Setup"},{"location":"#define-provisioning","text":"Once setup is complete, a provision specification is needed. This defines ssh-keys and one or more layouts to be provisioned. Create a file ogc.yml and place in the top level directory where ogc is run: name : ci # SSH Keys must be passwordless ssh-keys : public : ~/.ssh/id_rsa_libcloud.pub private : ~/.ssh/id_rsa_libcloud layouts : elastic-agent-sles : runs-on : sles-15 instance-size : e2-standard-8 username : root scripts : fixtures/ex_deploy_sles provider : google scale : 5 remote-path : /root/ogc include : - .ogc-cache exclude : - .git - .venv artifacts : /root/output/*.xml tags : - elastic-agent-8.1.x - sles-gcp This specification tells OGC to deploy 5 nodes running on Google\u2019s e2-standard-8 with SUSE 15 OS. The scripts section tells OGC where the template files/scripts are located that need to be uploaded to each node during the deployment phase.","title":"Define Provisioning"},{"location":"#provision-and-deploy","text":"OGC uses a client/server architecture to better handle scaling and concurrency needs. A celery server needs to be available prior launching nodes: $ ogc server Note : An alternative is to run this process in a separate docker container. Once the specification is set, environment variables configured and celery is running, execute a deployment in a new terminal: $ ogc launch Note : If the file is something other than ogc.yml append the --spec option to the launch command: $ ogc launch --spec my-custom-provision.yml","title":"Provision and Deploy"},{"location":"#next-steps","text":"Learn how to manage your deployments in our User Guide - Managing a deployment","title":"Next steps"},{"location":"commands/ogc-exec/","text":"NAME \u00b6 ogc-exec - Execute a command across node(s) SYNOPSIS \u00b6 ogc exec [OPTIONS] CMD DESCRIPTION \u00b6 Execute a command across node(s) OPTIONS \u00b6 --by-tag TEXT : Only run on nodes matching tag --by-name TEXT : Only run on nodes matching name","title":"ogc exec"},{"location":"commands/ogc-exec/#name","text":"ogc-exec - Execute a command across node(s)","title":"NAME"},{"location":"commands/ogc-exec/#synopsis","text":"ogc exec [OPTIONS] CMD","title":"SYNOPSIS"},{"location":"commands/ogc-exec/#description","text":"Execute a command across node(s)","title":"DESCRIPTION"},{"location":"commands/ogc-exec/#options","text":"--by-tag TEXT : Only run on nodes matching tag --by-name TEXT : Only run on nodes matching name","title":"OPTIONS"},{"location":"commands/ogc-inspect/","text":"NAME \u00b6 ogc-inspect - List nodes in your inventory SYNOPSIS \u00b6 ogc inspect [OPTIONS] DESCRIPTION \u00b6 List nodes in your inventory OPTIONS \u00b6 --id TEXT : Inspect node by DB ID --name TEXT : Inspect nodes by name, this can be a substring match --tag TEXT : Inspect nodes by tag --action-id TEXT : If set will only show the action output for a specific action ID","title":"ogc inspect"},{"location":"commands/ogc-inspect/#name","text":"ogc-inspect - List nodes in your inventory","title":"NAME"},{"location":"commands/ogc-inspect/#synopsis","text":"ogc inspect [OPTIONS]","title":"SYNOPSIS"},{"location":"commands/ogc-inspect/#description","text":"List nodes in your inventory","title":"DESCRIPTION"},{"location":"commands/ogc-inspect/#options","text":"--id TEXT : Inspect node by DB ID --name TEXT : Inspect nodes by name, this can be a substring match --tag TEXT : Inspect nodes by tag --action-id TEXT : If set will only show the action output for a specific action ID","title":"OPTIONS"},{"location":"commands/ogc-launch/","text":"NAME \u00b6 ogc-launch - Launches nodes from a provision specification SYNOPSIS \u00b6 ogc launch [OPTIONS] DESCRIPTION \u00b6 Launches nodes from a provision specification OPTIONS \u00b6 --spec TEXT : <!-- --> --with-deploy / --with-no-deploy : Also performs script deployments (default: Yes)","title":"ogc launch"},{"location":"commands/ogc-launch/#name","text":"ogc-launch - Launches nodes from a provision specification","title":"NAME"},{"location":"commands/ogc-launch/#synopsis","text":"ogc launch [OPTIONS]","title":"SYNOPSIS"},{"location":"commands/ogc-launch/#description","text":"Launches nodes from a provision specification","title":"DESCRIPTION"},{"location":"commands/ogc-launch/#options","text":"--spec TEXT : <!-- --> --with-deploy / --with-no-deploy : Also performs script deployments (default: Yes)","title":"OPTIONS"},{"location":"commands/ogc-log/","text":"NAME \u00b6 ogc-log - Stream log output SYNOPSIS \u00b6 ogc log [OPTIONS] DESCRIPTION \u00b6 Stream log output","title":"ogc log"},{"location":"commands/ogc-log/#name","text":"ogc-log - Stream log output","title":"NAME"},{"location":"commands/ogc-log/#synopsis","text":"ogc log [OPTIONS]","title":"SYNOPSIS"},{"location":"commands/ogc-log/#description","text":"Stream log output","title":"DESCRIPTION"},{"location":"commands/ogc-ls-key-pairs/","text":"NAME \u00b6 ogc-ls-key-pairs - List keypairs SYNOPSIS \u00b6 ogc ls-key-pairs [OPTIONS] DESCRIPTION \u00b6 List keypairs OPTIONS \u00b6 --filter TEXT : Filter by keypair name --provider TEXT : Provider to query","title":"ogc ls-key-pairs"},{"location":"commands/ogc-ls-key-pairs/#name","text":"ogc-ls-key-pairs - List keypairs","title":"NAME"},{"location":"commands/ogc-ls-key-pairs/#synopsis","text":"ogc ls-key-pairs [OPTIONS]","title":"SYNOPSIS"},{"location":"commands/ogc-ls-key-pairs/#description","text":"List keypairs","title":"DESCRIPTION"},{"location":"commands/ogc-ls-key-pairs/#options","text":"--filter TEXT : Filter by keypair name --provider TEXT : Provider to query","title":"OPTIONS"},{"location":"commands/ogc-ls/","text":"NAME \u00b6 ogc-ls - List nodes in your inventory SYNOPSIS \u00b6 ogc ls [OPTIONS] DESCRIPTION \u00b6 List nodes in your inventory OPTIONS \u00b6 --by-tag TEXT : List nodes by tag --by-name TEXT : List nodes by name, this can be a substring match","title":"ogc ls"},{"location":"commands/ogc-ls/#name","text":"ogc-ls - List nodes in your inventory","title":"NAME"},{"location":"commands/ogc-ls/#synopsis","text":"ogc ls [OPTIONS]","title":"SYNOPSIS"},{"location":"commands/ogc-ls/#description","text":"List nodes in your inventory","title":"DESCRIPTION"},{"location":"commands/ogc-ls/#options","text":"--by-tag TEXT : List nodes by tag --by-name TEXT : List nodes by name, this can be a substring match","title":"OPTIONS"},{"location":"commands/ogc-pull-artifacts/","text":"NAME \u00b6 ogc-pull-artifacts - Download artifacts from node SYNOPSIS \u00b6 ogc pull-artifacts [OPTIONS] NAME DESCRIPTION \u00b6 Download artifacts from node","title":"ogc pull-artifacts"},{"location":"commands/ogc-pull-artifacts/#name","text":"ogc-pull-artifacts - Download artifacts from node","title":"NAME"},{"location":"commands/ogc-pull-artifacts/#synopsis","text":"ogc pull-artifacts [OPTIONS] NAME","title":"SYNOPSIS"},{"location":"commands/ogc-pull-artifacts/#description","text":"Download artifacts from node","title":"DESCRIPTION"},{"location":"commands/ogc-pull-files/","text":"NAME \u00b6 ogc-pull-files - Scp files or directories from node SYNOPSIS \u00b6 ogc pull-files [OPTIONS] NAME DST SRC DESCRIPTION \u00b6 Scp files or directories from node","title":"ogc pull-files"},{"location":"commands/ogc-pull-files/#name","text":"ogc-pull-files - Scp files or directories from node","title":"NAME"},{"location":"commands/ogc-pull-files/#synopsis","text":"ogc pull-files [OPTIONS] NAME DST SRC","title":"SYNOPSIS"},{"location":"commands/ogc-pull-files/#description","text":"Scp files or directories from node","title":"DESCRIPTION"},{"location":"commands/ogc-push-files/","text":"NAME \u00b6 ogc-push-files - Scp files or directories to node SYNOPSIS \u00b6 ogc push-files [OPTIONS] NAME SRC DST DESCRIPTION \u00b6 Scp files or directories to node OPTIONS \u00b6 --exclude TEXT : Exclude files/directories when uploading","title":"ogc push-files"},{"location":"commands/ogc-push-files/#name","text":"ogc-push-files - Scp files or directories to node","title":"NAME"},{"location":"commands/ogc-push-files/#synopsis","text":"ogc push-files [OPTIONS] NAME SRC DST","title":"SYNOPSIS"},{"location":"commands/ogc-push-files/#description","text":"Scp files or directories to node","title":"DESCRIPTION"},{"location":"commands/ogc-push-files/#options","text":"--exclude TEXT : Exclude files/directories when uploading","title":"OPTIONS"},{"location":"commands/ogc-rm-all/","text":"NAME \u00b6 ogc-rm-all - Destroys everything. SYNOPSIS \u00b6 ogc rm-all [OPTIONS] DESCRIPTION \u00b6 Destroys everything. Use with caution. OPTIONS \u00b6 --force / --no-force : Force removal regardless of connectivity","title":"ogc rm-all"},{"location":"commands/ogc-rm-all/#name","text":"ogc-rm-all - Destroys everything.","title":"NAME"},{"location":"commands/ogc-rm-all/#synopsis","text":"ogc rm-all [OPTIONS]","title":"SYNOPSIS"},{"location":"commands/ogc-rm-all/#description","text":"Destroys everything. Use with caution.","title":"DESCRIPTION"},{"location":"commands/ogc-rm-all/#options","text":"--force / --no-force : Force removal regardless of connectivity","title":"OPTIONS"},{"location":"commands/ogc-rm-key-pairs/","text":"NAME \u00b6 ogc-rm-key-pairs - Remove keypairs SYNOPSIS \u00b6 ogc rm-key-pairs [OPTIONS] DESCRIPTION \u00b6 Remove keypairs OPTIONS \u00b6 --filter TEXT : Filter by keypair name --provider TEXT : Provider to query","title":"ogc rm-key-pairs"},{"location":"commands/ogc-rm-key-pairs/#name","text":"ogc-rm-key-pairs - Remove keypairs","title":"NAME"},{"location":"commands/ogc-rm-key-pairs/#synopsis","text":"ogc rm-key-pairs [OPTIONS]","title":"SYNOPSIS"},{"location":"commands/ogc-rm-key-pairs/#description","text":"Remove keypairs","title":"DESCRIPTION"},{"location":"commands/ogc-rm-key-pairs/#options","text":"--filter TEXT : Filter by keypair name --provider TEXT : Provider to query","title":"OPTIONS"},{"location":"commands/ogc-rm/","text":"NAME \u00b6 ogc-rm - Destroys a node and its associated keys,... SYNOPSIS \u00b6 ogc rm [OPTIONS] DESCRIPTION \u00b6 Destroys a node and its associated keys, storage, etc. OPTIONS \u00b6 --name TEXT : [required] --force / --no-force : Force removal regardless of connectivity","title":"ogc rm"},{"location":"commands/ogc-rm/#name","text":"ogc-rm - Destroys a node and its associated keys,...","title":"NAME"},{"location":"commands/ogc-rm/#synopsis","text":"ogc rm [OPTIONS]","title":"SYNOPSIS"},{"location":"commands/ogc-rm/#description","text":"Destroys a node and its associated keys, storage, etc.","title":"DESCRIPTION"},{"location":"commands/ogc-rm/#options","text":"--name TEXT : [required] --force / --no-force : Force removal regardless of connectivity","title":"OPTIONS"},{"location":"commands/ogc-server/","text":"NAME \u00b6 ogc-server - Starts the tasks server SYNOPSIS \u00b6 ogc server [OPTIONS] DESCRIPTION \u00b6 Starts the tasks server","title":"ogc server"},{"location":"commands/ogc-server/#name","text":"ogc-server - Starts the tasks server","title":"NAME"},{"location":"commands/ogc-server/#synopsis","text":"ogc server [OPTIONS]","title":"SYNOPSIS"},{"location":"commands/ogc-server/#description","text":"Starts the tasks server","title":"DESCRIPTION"},{"location":"commands/ogc-ssh/","text":"NAME \u00b6 ogc-ssh - Login to a node SYNOPSIS \u00b6 ogc ssh [OPTIONS] NAME DESCRIPTION \u00b6 Login to a node","title":"ogc ssh"},{"location":"commands/ogc-ssh/#name","text":"ogc-ssh - Login to a node","title":"NAME"},{"location":"commands/ogc-ssh/#synopsis","text":"ogc ssh [OPTIONS] NAME","title":"SYNOPSIS"},{"location":"commands/ogc-ssh/#description","text":"Login to a node","title":"DESCRIPTION"},{"location":"commands/ogc-status/","text":"NAME \u00b6 ogc-status - Get status of deployment SYNOPSIS \u00b6 ogc status [OPTIONS] DESCRIPTION \u00b6 Get status of deployment OPTIONS \u00b6 --reconcile / --no-reconcile : Attempt to fix deployment to match scale --spec TEXT :","title":"ogc status"},{"location":"commands/ogc-status/#name","text":"ogc-status - Get status of deployment","title":"NAME"},{"location":"commands/ogc-status/#synopsis","text":"ogc status [OPTIONS]","title":"SYNOPSIS"},{"location":"commands/ogc-status/#description","text":"Get status of deployment","title":"DESCRIPTION"},{"location":"commands/ogc-status/#options","text":"--reconcile / --no-reconcile : Attempt to fix deployment to match scale --spec TEXT :","title":"OPTIONS"},{"location":"commands/ogc/","text":"NAME \u00b6 ogc - Just a simple provisioner SYNOPSIS \u00b6 ogc [OPTIONS] COMMAND [ARGS]... DESCRIPTION \u00b6 Just a simple provisioner COMMANDS \u00b6 rm Destroys a node and its associated keys,... See ogc-rm(1) for full documentation on the rm command. rm-all Destroys everything. See ogc-rm-all(1) for full documentation on the rm-all command. rm-key-pairs Remove keypairs See ogc-rm-key-pairs(1) for full documentation on the rm-key-pairs command. inspect List nodes in your inventory See ogc-inspect(1) for full documentation on the inspect command. launch Launches nodes from a provision specification See ogc-launch(1) for full documentation on the launch command. ls List nodes in your inventory See ogc-ls(1) for full documentation on the ls command. ls-key-pairs List keypairs See ogc-ls-key-pairs(1) for full documentation on the ls-key-pairs command. log Stream log output See ogc-log(1) for full documentation on the log command. server Starts the tasks server See ogc-server(1) for full documentation on the server command. ssh Login to a node See ogc-ssh(1) for full documentation on the ssh command. push-files Scp files or directories to node See ogc-push-files(1) for full documentation on the push-files command. pull-files Scp files or directories from node See ogc-pull-files(1) for full documentation on the pull-files command. pull-artifacts Download artifacts from node See ogc-pull-artifacts(1) for full documentation on the pull-artifacts command. exec Execute a command across node(s) See ogc-exec(1) for full documentation on the exec command. status Get status of deployment See ogc-status(1) for full documentation on the status command.","title":"ogc"},{"location":"commands/ogc/#name","text":"ogc - Just a simple provisioner","title":"NAME"},{"location":"commands/ogc/#synopsis","text":"ogc [OPTIONS] COMMAND [ARGS]...","title":"SYNOPSIS"},{"location":"commands/ogc/#description","text":"Just a simple provisioner","title":"DESCRIPTION"},{"location":"commands/ogc/#commands","text":"rm Destroys a node and its associated keys,... See ogc-rm(1) for full documentation on the rm command. rm-all Destroys everything. See ogc-rm-all(1) for full documentation on the rm-all command. rm-key-pairs Remove keypairs See ogc-rm-key-pairs(1) for full documentation on the rm-key-pairs command. inspect List nodes in your inventory See ogc-inspect(1) for full documentation on the inspect command. launch Launches nodes from a provision specification See ogc-launch(1) for full documentation on the launch command. ls List nodes in your inventory See ogc-ls(1) for full documentation on the ls command. ls-key-pairs List keypairs See ogc-ls-key-pairs(1) for full documentation on the ls-key-pairs command. log Stream log output See ogc-log(1) for full documentation on the log command. server Starts the tasks server See ogc-server(1) for full documentation on the server command. ssh Login to a node See ogc-ssh(1) for full documentation on the ssh command. push-files Scp files or directories to node See ogc-push-files(1) for full documentation on the push-files command. pull-files Scp files or directories from node See ogc-pull-files(1) for full documentation on the pull-files command. pull-artifacts Download artifacts from node See ogc-pull-artifacts(1) for full documentation on the pull-artifacts command. exec Execute a command across node(s) See ogc-exec(1) for full documentation on the exec command. status Get status of deployment See ogc-status(1) for full documentation on the status command.","title":"COMMANDS"},{"location":"user-guide/defining-layouts/","text":"Defining Layouts \u00b6 Learn the layout specification and how to create your own provisioning layouts. All layouts reside under the layouts key in the provision specification: layouts: elastic-agent-sles: runs-on: sles-15 instance-size: e2-standard-8 username: root scripts: fixtures/ex_deploy_sles provider: google scale: 5 remote-path: /root/ogc include: - .ogc-cache exclude: - .git - .venv artifacts: /root/output/*.xml tags: - elastic-agent-8.1.x - sles-gcp Each layout has a friendly name associated as seen by elastic-agent-sles . The next section is going to go over each option and describe its meaning. provider Define which cloud the layout will operate in. Currently supported options are aws and google . runs-on Define the base OS image to be deployed on to the nodes. The current supported list of names are: AWS Google ubuntu-latest ubuntu-latest ubuntu-2004 ubuntu-2004 ubuntu-1804 ubuntu-1804 centos-latest sles-latest centos-8 sles-15 sles-latest debian-latest sles-15 debian-10 debian-latest debian-9 debian-11 debian-10 instance-size Define the machine size, this is dependent on which provider is chosen. The instance-size correlates with the instance size naming for each cloud. For example, on AWS you would use instance-size: c5.4xlarge and in Google\u2019s case, instance-size: e2-standard-8 . username The ssh user to use when deploying and accessing the nodes. This is also somewhat dependent on which provider is used. In the case of Google , any username can be given. In the case of AWS , the base machines have a pre-loaded user that must be used: AWS Username ubuntu ubuntu centos ec2-user debian admin scripts The location on your machine where templates/scripts resides. These will be uploaded and executed during the deployment phase. Note : See scripting for more information. scale How many nodes of each layout to deploy. This is also referenced during a deployment reconciliation phase. remote-path (optional) If set, any uploads/downloads outside of what\u2019s defined in scripts will be placed in that remote path. include (optional) A list of files/wildcards to include in the upload exclude (optional) A list of files/wildcards to exclude in the upload artifacts (optional) The remote path where script execution output is stored. This is used when pulling artifacts with ogc pull-artifacts and also utilized during node teardown. This will download any artifacts found into artifacts/instance-name/ . tags (optional) Define tags for each layout, allows additional filtering capabilities and deployment options when used with ogc ls and ogc exec Variants \u00b6 OGC supports the concept of variants. In OGC\u2019s case, variants are handled by multiple provision spec files and are then merged in a merge-left fashion. What this means is that we can take a base spec file such as: name : ci ssh-keys : public : id_rsa.pub private : id_rsa layouts : elastic-agent-sles : runs-on : sles-15 instance-size : e2-standard-8 username : root scripts : fixtures/ex_deploy_sles provider : google scale : 5 remote-path : /root/ogc include : - .ogc-cache exclude : - .git - .venv artifacts : /root/output/*.xml tags : - elastic-agent-8.1.x - sles-gcp elastic-agent-ubuntu : runs-on : ubuntu-latest instance-size : e2-standard-8 username : root scripts : fixtures/ex_deploy_ubuntu provider : google scale : 5 remote-path : /root/ogc exclude : - .git - .venv artifacts : /root/output/*.xml tags : - elastic-agent-8.1.x - ubuntu-gcp The name of the file doesn\u2019t matter, we\u2019ll call this file base-spec.yml . Now if we need to change certain aspects of this base deploy specification we can define a second YAML file, we\u2019ll call it ubuntu-1804-no-sles.yml . In this example, let\u2019s change the username and runs-on for the ubuntu layout, and let\u2019s also remove the sles layout: layouts : elastic-agent-sles : {} elastic-agent-ubuntu : runs-on : ubuntu-1804 username : ubuntu The merging of the specifications will remove any keys that exist if the value of the key is {} (signaling an empty stanza). The remaining keys that match up with the original spec will then be overridden and the rest of the specification is left untouched. Adding new layouts is just a matter of defining another section under layouts in the additional spec files passed to OGC.","title":"Defining Layouts"},{"location":"user-guide/defining-layouts/#defining-layouts","text":"Learn the layout specification and how to create your own provisioning layouts. All layouts reside under the layouts key in the provision specification: layouts: elastic-agent-sles: runs-on: sles-15 instance-size: e2-standard-8 username: root scripts: fixtures/ex_deploy_sles provider: google scale: 5 remote-path: /root/ogc include: - .ogc-cache exclude: - .git - .venv artifacts: /root/output/*.xml tags: - elastic-agent-8.1.x - sles-gcp Each layout has a friendly name associated as seen by elastic-agent-sles . The next section is going to go over each option and describe its meaning. provider Define which cloud the layout will operate in. Currently supported options are aws and google . runs-on Define the base OS image to be deployed on to the nodes. The current supported list of names are: AWS Google ubuntu-latest ubuntu-latest ubuntu-2004 ubuntu-2004 ubuntu-1804 ubuntu-1804 centos-latest sles-latest centos-8 sles-15 sles-latest debian-latest sles-15 debian-10 debian-latest debian-9 debian-11 debian-10 instance-size Define the machine size, this is dependent on which provider is chosen. The instance-size correlates with the instance size naming for each cloud. For example, on AWS you would use instance-size: c5.4xlarge and in Google\u2019s case, instance-size: e2-standard-8 . username The ssh user to use when deploying and accessing the nodes. This is also somewhat dependent on which provider is used. In the case of Google , any username can be given. In the case of AWS , the base machines have a pre-loaded user that must be used: AWS Username ubuntu ubuntu centos ec2-user debian admin scripts The location on your machine where templates/scripts resides. These will be uploaded and executed during the deployment phase. Note : See scripting for more information. scale How many nodes of each layout to deploy. This is also referenced during a deployment reconciliation phase. remote-path (optional) If set, any uploads/downloads outside of what\u2019s defined in scripts will be placed in that remote path. include (optional) A list of files/wildcards to include in the upload exclude (optional) A list of files/wildcards to exclude in the upload artifacts (optional) The remote path where script execution output is stored. This is used when pulling artifacts with ogc pull-artifacts and also utilized during node teardown. This will download any artifacts found into artifacts/instance-name/ . tags (optional) Define tags for each layout, allows additional filtering capabilities and deployment options when used with ogc ls and ogc exec","title":"Defining Layouts"},{"location":"user-guide/defining-layouts/#variants","text":"OGC supports the concept of variants. In OGC\u2019s case, variants are handled by multiple provision spec files and are then merged in a merge-left fashion. What this means is that we can take a base spec file such as: name : ci ssh-keys : public : id_rsa.pub private : id_rsa layouts : elastic-agent-sles : runs-on : sles-15 instance-size : e2-standard-8 username : root scripts : fixtures/ex_deploy_sles provider : google scale : 5 remote-path : /root/ogc include : - .ogc-cache exclude : - .git - .venv artifacts : /root/output/*.xml tags : - elastic-agent-8.1.x - sles-gcp elastic-agent-ubuntu : runs-on : ubuntu-latest instance-size : e2-standard-8 username : root scripts : fixtures/ex_deploy_ubuntu provider : google scale : 5 remote-path : /root/ogc exclude : - .git - .venv artifacts : /root/output/*.xml tags : - elastic-agent-8.1.x - ubuntu-gcp The name of the file doesn\u2019t matter, we\u2019ll call this file base-spec.yml . Now if we need to change certain aspects of this base deploy specification we can define a second YAML file, we\u2019ll call it ubuntu-1804-no-sles.yml . In this example, let\u2019s change the username and runs-on for the ubuntu layout, and let\u2019s also remove the sles layout: layouts : elastic-agent-sles : {} elastic-agent-ubuntu : runs-on : ubuntu-1804 username : ubuntu The merging of the specifications will remove any keys that exist if the value of the key is {} (signaling an empty stanza). The remaining keys that match up with the original spec will then be overridden and the rest of the specification is left untouched. Adding new layouts is just a matter of defining another section under layouts in the additional spec files passed to OGC.","title":"Variants"},{"location":"user-guide/managing-nodes/","text":"Managing a Deployment \u00b6 Learn how to list, inspect, access and debug your node deployments. Listing Nodes \u00b6 To list nodes in your deployment, run the following: $ ogc ls Which gives a table output of current node deployments: \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2503 10 Nodes \u2503 Name \u2503 Status \u2503 Connection \u2503 Tags \u2503 Actions \u2503 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502 20 \u2502 ogc-87ba30fc-elastic-agent-sles \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@34.123.103.9 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 sles-gcp \u2502 \u2502 \u2502 34 \u2502 ogc-b3befadc-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@35.184.43.81 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 35 \u2502 ogc-d54a5848-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@34.121.133.188 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 36 \u2502 ogc-cbb9d5bc-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@34.67.108.205 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 21 \u2502 ogc-51b971ad-elastic-agent-sles \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@35.239.181.14 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 sles-gcp \u2502 \u2502 \u2502 22 \u2502 ogc-c4f812b7-elastic-agent-sles \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@35.184.34.2 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 sles-gcp \u2502 \u2502 \u2502 23 \u2502 ogc-7c8cb271-elastic-agent-sles \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@34.72.237.134 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 sles-gcp \u2502 \u2502 \u2502 24 \u2502 ogc-d4467204-elastic-agent-sles \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@34.132.30.47 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 sles-gcp \u2502 \u2502 \u2502 37 \u2502 ogc-92f1c5ec-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@104.197.37.199 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 38 \u2502 ogc-d7cd61a7-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@35.225.239.252 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 You can further drill down with a couple of options: To filter by-tag run: $ ogc ls --by-tag ubuntu-gcp \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2503 5 Nodes \u2503 Name \u2503 Status \u2503 Connection \u2503 Tags \u2503 Actions \u2503 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502 34 \u2502 ogc-b3befadc-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@35.184.43.81 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 35 \u2502 ogc-d54a5848-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@34.121.133.188 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 36 \u2502 ogc-cbb9d5bc-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@34.67.108.205 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 37 \u2502 ogc-92f1c5ec-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@104.197.37.199 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 38 \u2502 ogc-d7cd61a7-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@35.225.239.252 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Accessing nodes \u00b6 OGC provides a helper command for easily accessing any of the nodes in your deployment. To login to one of the above nodes ogc-d7cd61a7-elastic-agent-ubuntu run: $ ogc ssh ogc-d7cd61a7-elastic-agent-ubuntu ... ssh output ... root@ogc-d7cd61a7-elastic-agent-ubuntu:~# Executing commands \u00b6 Running arbitrary commands can be accomplished with: $ ogc exec --by-name ogc-d7cd61a7-elastic-agent-ubuntu 'ls -l /' Or if tags are defined, run a command across a set of machines: $ ogc exec --by-tag ubuntu-gcp 'touch this_is_an_ubuntu_machine.txt' Downloading files \u00b6 There are 2 ways to download files, the first is to use ogc pull-files , this gives you the ability to download any arbitrary files: $ ogc pull-files ogc-d7cd61a7-elastic-agent-ubuntu im_downloaded_computer.txt im_on_a_computer.txt $ stat im_downloaded_computer.txt 16777221 24809112 -rw-r--r-- 1 adam staff 0 0 \"Mar 24 11:56:24 2022\" \"Mar 24 11:55:16 2022\" \"Mar 24 11:56:24 2022\" \"Mar 24 11:55:16 2022\" 4096 0 0 im_downloaded_computer.txt Another way is if the artifacts key is defined in a layout. To grab files defined by that artifacts option run the following: $ ogc pull-artifacts ogc-d7cd61a7-elastic-agent-ubuntu By default, artifacts are stored in $(pwd)/artifacts/ogc-d7cd61a7-elastic-agent-ubuntu tree artifacts/ogc-d7cd61a7-elastic-agent-ubuntu/ artifacts/ogc-d7cd61a7-elastic-agent-ubuntu/ \u2514\u2500\u2500 test.xml 0 directories, 1 file Uploading files \u00b6 OGC provides a simple way to upload arbitrary files to a node: $ ogc push-files ogc-d7cd61a7-elastic-agent-ubuntu im_downloaded_computer.txt dl.txt Optionally, if --exclude is provided, uploading files will ignore any wildcards matched. Passing multiple --exclude is supported and will be added to the list of excludes during upload. Useful if uploading directories and want to ignore things like .git and .venv . Inspecting nodes \u00b6 Each action performed on a node is tracked. This allows you to quickly investigate why scripts failed. To inspect a node and see action results run: $ ogc inspect --id 38 This will return the following output: Deploy Details: ogc-d7cd61a7-elastic-agent-ubuntu [3] Successful Actions: (id: 90) Out: 2022-03-24 12:37:08.657289 '/usr/local/bin/pacman' -> '/usr/local/bin/pacapt' Reading package lists... Building dependency tree... Reading state information... nano is already the newest version (2.9.3-2). nano set to manually installed. The following package was automatically installed and is no longer required: libnuma1 Use 'apt autoremove' to remove it. 0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded. If multiple actions exist, further drill down into the action you want ( seen here \u201c(id: 90) Out: 2022-03-24 12:37:08.\u201d in our example ): $ ogc inspect --id 38 --action-id 90 Syncing a deployment \u00b6 In some cases nodes will fail to deploy or you remembered you needed more than 5 nodes or maybe you need less nodes than what the original scale was set. In all these cases, OGC provides a way to keep the deployment in sync with the layouts. To get an idea of the health of the deployment, run: $ ogc status The output returned will be a table displaying what\u2019s deployed, the scale, and if there are any remaining nodes left: Deployment Status: Healthy \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2503 Name \u2503 Deployed \u2503 Scale \u2503 Remaining \u2503 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502 elastic-agent-sles \u2502 5 \u2502 5 \u2502 0 \u2502 \u2502 elastic-agent-ubuntu \u2502 5 \u2502 5 \u2502 0 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 In cases where you want to add more nodes, update your layout and increase the scale option, in this case we want to add 10 more nodes to our elastic-agent-sles layout: Deployment Status: Degraded \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2503 Name \u2503 Deployed \u2503 Scale \u2503 Remaining \u2503 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502 elastic-agent-sles \u2502 5 \u2502 15 \u2502 10 \u2502 \u2502 elastic-agent-ubuntu \u2502 5 \u2502 5 \u2502 0 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Or another case where we need to reduce the number of nodes from 5 to 3: Deployment Status: Degraded \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2503 Name \u2503 Deployed \u2503 Scale \u2503 Remaining \u2503 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502 elastic-agent-sles \u2502 5 \u2502 3 \u2502 -2 \u2502 \u2502 elastic-agent-ubuntu \u2502 5 \u2502 3 \u2502 -2 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 To perform the sync, run the following: $ ogc status --reconcile And the output will show OGC destroying 2 nodes from each layout: 2022-03-24 at 11:52:37 | INFO Reconciling: [elastic-agent-sles, elastic-agent-ubuntu] 2022-03-24 at 11:52:37 | INFO Destroying: ogc-87ba30fc-elastic-agent-sles 2022-03-24 at 11:52:37 | INFO Destroying: ogc-51b971ad-elastic-agent-sles 2022-03-24 at 11:52:37 | INFO Destroying: ogc-b3befadc-elastic-agent-ubuntu 2022-03-24 at 11:52:37 | INFO Destroying: ogc-d54a5848-elastic-agent-ubuntu Destroying nodes \u00b6 OGC allows destroying of individual or a full blown cleanup. To remove a single node we run: $ ogc rm ogc-d7cd61a7-elastic-agent-ubuntu --force Or if we wanted to do a full teardown, run: $ ogc rm-all --force","title":"Managing a deployment"},{"location":"user-guide/managing-nodes/#managing-a-deployment","text":"Learn how to list, inspect, access and debug your node deployments.","title":"Managing a Deployment"},{"location":"user-guide/managing-nodes/#listing-nodes","text":"To list nodes in your deployment, run the following: $ ogc ls Which gives a table output of current node deployments: \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2503 10 Nodes \u2503 Name \u2503 Status \u2503 Connection \u2503 Tags \u2503 Actions \u2503 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502 20 \u2502 ogc-87ba30fc-elastic-agent-sles \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@34.123.103.9 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 sles-gcp \u2502 \u2502 \u2502 34 \u2502 ogc-b3befadc-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@35.184.43.81 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 35 \u2502 ogc-d54a5848-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@34.121.133.188 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 36 \u2502 ogc-cbb9d5bc-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@34.67.108.205 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 21 \u2502 ogc-51b971ad-elastic-agent-sles \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@35.239.181.14 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 sles-gcp \u2502 \u2502 \u2502 22 \u2502 ogc-c4f812b7-elastic-agent-sles \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@35.184.34.2 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 sles-gcp \u2502 \u2502 \u2502 23 \u2502 ogc-7c8cb271-elastic-agent-sles \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@34.72.237.134 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 sles-gcp \u2502 \u2502 \u2502 24 \u2502 ogc-d4467204-elastic-agent-sles \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@34.132.30.47 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 sles-gcp \u2502 \u2502 \u2502 37 \u2502 ogc-92f1c5ec-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@104.197.37.199 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 38 \u2502 ogc-d7cd61a7-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@35.225.239.252 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 You can further drill down with a couple of options: To filter by-tag run: $ ogc ls --by-tag ubuntu-gcp \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2503 5 Nodes \u2503 Name \u2503 Status \u2503 Connection \u2503 Tags \u2503 Actions \u2503 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502 34 \u2502 ogc-b3befadc-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@35.184.43.81 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 35 \u2502 ogc-d54a5848-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@34.121.133.188 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 36 \u2502 ogc-cbb9d5bc-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@34.67.108.205 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 37 \u2502 ogc-92f1c5ec-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@104.197.37.199 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2502 38 \u2502 ogc-d7cd61a7-elastic-agent-ubuntu \u2502 running \u2502 ssh -i /Users/adam/.ssh/id_rsa_libcloud root@35.225.239.252 \u2502 elastic-agent-8.1.x, \u2502 pass: \u2714 fail: 0 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ubuntu-gcp \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Listing Nodes"},{"location":"user-guide/managing-nodes/#accessing-nodes","text":"OGC provides a helper command for easily accessing any of the nodes in your deployment. To login to one of the above nodes ogc-d7cd61a7-elastic-agent-ubuntu run: $ ogc ssh ogc-d7cd61a7-elastic-agent-ubuntu ... ssh output ... root@ogc-d7cd61a7-elastic-agent-ubuntu:~#","title":"Accessing nodes"},{"location":"user-guide/managing-nodes/#executing-commands","text":"Running arbitrary commands can be accomplished with: $ ogc exec --by-name ogc-d7cd61a7-elastic-agent-ubuntu 'ls -l /' Or if tags are defined, run a command across a set of machines: $ ogc exec --by-tag ubuntu-gcp 'touch this_is_an_ubuntu_machine.txt'","title":"Executing commands"},{"location":"user-guide/managing-nodes/#downloading-files","text":"There are 2 ways to download files, the first is to use ogc pull-files , this gives you the ability to download any arbitrary files: $ ogc pull-files ogc-d7cd61a7-elastic-agent-ubuntu im_downloaded_computer.txt im_on_a_computer.txt $ stat im_downloaded_computer.txt 16777221 24809112 -rw-r--r-- 1 adam staff 0 0 \"Mar 24 11:56:24 2022\" \"Mar 24 11:55:16 2022\" \"Mar 24 11:56:24 2022\" \"Mar 24 11:55:16 2022\" 4096 0 0 im_downloaded_computer.txt Another way is if the artifacts key is defined in a layout. To grab files defined by that artifacts option run the following: $ ogc pull-artifacts ogc-d7cd61a7-elastic-agent-ubuntu By default, artifacts are stored in $(pwd)/artifacts/ogc-d7cd61a7-elastic-agent-ubuntu tree artifacts/ogc-d7cd61a7-elastic-agent-ubuntu/ artifacts/ogc-d7cd61a7-elastic-agent-ubuntu/ \u2514\u2500\u2500 test.xml 0 directories, 1 file","title":"Downloading files"},{"location":"user-guide/managing-nodes/#uploading-files","text":"OGC provides a simple way to upload arbitrary files to a node: $ ogc push-files ogc-d7cd61a7-elastic-agent-ubuntu im_downloaded_computer.txt dl.txt Optionally, if --exclude is provided, uploading files will ignore any wildcards matched. Passing multiple --exclude is supported and will be added to the list of excludes during upload. Useful if uploading directories and want to ignore things like .git and .venv .","title":"Uploading files"},{"location":"user-guide/managing-nodes/#inspecting-nodes","text":"Each action performed on a node is tracked. This allows you to quickly investigate why scripts failed. To inspect a node and see action results run: $ ogc inspect --id 38 This will return the following output: Deploy Details: ogc-d7cd61a7-elastic-agent-ubuntu [3] Successful Actions: (id: 90) Out: 2022-03-24 12:37:08.657289 '/usr/local/bin/pacman' -> '/usr/local/bin/pacapt' Reading package lists... Building dependency tree... Reading state information... nano is already the newest version (2.9.3-2). nano set to manually installed. The following package was automatically installed and is no longer required: libnuma1 Use 'apt autoremove' to remove it. 0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded. If multiple actions exist, further drill down into the action you want ( seen here \u201c(id: 90) Out: 2022-03-24 12:37:08.\u201d in our example ): $ ogc inspect --id 38 --action-id 90","title":"Inspecting nodes"},{"location":"user-guide/managing-nodes/#syncing-a-deployment","text":"In some cases nodes will fail to deploy or you remembered you needed more than 5 nodes or maybe you need less nodes than what the original scale was set. In all these cases, OGC provides a way to keep the deployment in sync with the layouts. To get an idea of the health of the deployment, run: $ ogc status The output returned will be a table displaying what\u2019s deployed, the scale, and if there are any remaining nodes left: Deployment Status: Healthy \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2503 Name \u2503 Deployed \u2503 Scale \u2503 Remaining \u2503 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502 elastic-agent-sles \u2502 5 \u2502 5 \u2502 0 \u2502 \u2502 elastic-agent-ubuntu \u2502 5 \u2502 5 \u2502 0 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 In cases where you want to add more nodes, update your layout and increase the scale option, in this case we want to add 10 more nodes to our elastic-agent-sles layout: Deployment Status: Degraded \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2503 Name \u2503 Deployed \u2503 Scale \u2503 Remaining \u2503 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502 elastic-agent-sles \u2502 5 \u2502 15 \u2502 10 \u2502 \u2502 elastic-agent-ubuntu \u2502 5 \u2502 5 \u2502 0 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Or another case where we need to reduce the number of nodes from 5 to 3: Deployment Status: Degraded \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2503 Name \u2503 Deployed \u2503 Scale \u2503 Remaining \u2503 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502 elastic-agent-sles \u2502 5 \u2502 3 \u2502 -2 \u2502 \u2502 elastic-agent-ubuntu \u2502 5 \u2502 3 \u2502 -2 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 To perform the sync, run the following: $ ogc status --reconcile And the output will show OGC destroying 2 nodes from each layout: 2022-03-24 at 11:52:37 | INFO Reconciling: [elastic-agent-sles, elastic-agent-ubuntu] 2022-03-24 at 11:52:37 | INFO Destroying: ogc-87ba30fc-elastic-agent-sles 2022-03-24 at 11:52:37 | INFO Destroying: ogc-51b971ad-elastic-agent-sles 2022-03-24 at 11:52:37 | INFO Destroying: ogc-b3befadc-elastic-agent-ubuntu 2022-03-24 at 11:52:37 | INFO Destroying: ogc-d54a5848-elastic-agent-ubuntu","title":"Syncing a deployment"},{"location":"user-guide/managing-nodes/#destroying-nodes","text":"OGC allows destroying of individual or a full blown cleanup. To remove a single node we run: $ ogc rm ogc-d7cd61a7-elastic-agent-ubuntu --force Or if we wanted to do a full teardown, run: $ ogc rm-all --force","title":"Destroying nodes"},{"location":"user-guide/scripting/","text":"Scripting \u00b6 All deployments have the ability to execute scripts once a node becomes available. Before starting \u00b6 A couple of things to keep in mind: All scripts are executed in order based on the filenames. It is recommended to create scripts with a numbered prefix, for example: - scripts/ - 01-install-deps - 02-configure-services There is a special reserved filename teardown , if this file exists it will only be executed during a removal of a node. This is useful for any cleanup actions that may need to be run, such as removing test users, un-enrolling from a service, etc. Writing scripts \u00b6 Scripts can be written in any language, it is up to you to configure the nodes so that any runtimes and library dependencies are met on the target node for your script to execute in. One way to accomplish this is to create 01-setup-env bash script: #!/bin/bash echo \"Installing python3 on ubuntu\" sudo apt-get update sudo apt-get install -qyf python3 sudo pip install sh Then in subsequent scripts, using python3 is available. For example, in file 02-run-cmd-in-python : #!/usr/bin/env python3 import sh sh . ls ( '/' ) sh . cp ( '-a' , 'mydir' , 'anotherdir' ) Templating \u00b6 OGC provides some additional capabilities through templating. Under the hood python-mako is used for the parsing. With templating, you have the ability to query the underlying database to gather node information. Because mako supports the importing of python modules and our OGC environment is already exposed, we can access our db module and use some helper methods. #!/bin/bash <%namespace name = \"db\" module = \"ogc.db\" /> echo \"\" % for node in db.by_tag ( 'sles' ) : echo \"[ID: ${ node .id } ] Name: ${ node .instance_name } || Connection: ${ node .username } @ ${ node .public_ip } || Provider: ${ node .provider } \" % endfor echo \"\" The runtime environment is also available within the template context. In one example, we can export the following into our .env file and reference those in the templates: OGC_ELASTIC_AGENT_VERSION OGC_ELASTIC_AGENT_SHA OGC_ELASTIC_AGENT_VERSION OGC_FLEET_URL OGC_FLEET_ENROLLMENT_TOKEN See the below example for downloading elastic-agent and enrolling it into a fleet server. The variable exposed to all templates for accessing the environment variables is env #!/bin/bash <%namespace name = \"utils\" file = \"/functions.mako\" /> <% url = \"https://staging.elastic.co/%s-%s/downloads/beats/elastic-agent/elastic-agent-%s-linux-x86_64.tar.gz\" % ( env [ 'OGC_ELASTIC_AGENT_VERSION' ] , env [ 'OGC_ELASTIC_AGENT_SHA' ] , env [ 'OGC_ELASTIC_AGENT_VERSION' ]) %> ${ utils .setup_env() } ${ utils .install_pkgs([ 'nano' ]) } ${ utils .download(url, 'elastic-agent.tar.gz' ) } ${ utils .extract( 'elastic-agent.tar.gz' ) } mv elastic-agent- ${ env [ 'OGC_ELASTIC_AGENT_VERSION' ] } -linux-x86_64 elastic-agent cd elastic-agent && ./elastic-agent install -f --url = ${ env [ 'OGC_FLEET_URL' ] } --enrollment-token = ${ env [ 'OGC_FLEET_ENROLLMENT_TOKEN' ] } Reusable helpers \u00b6 In the above example we reference a file called /functions.mako this is just another template file that sits just outside of our defined scripts , for example, if our scripts is defined to be in scripts/my_ubuntu_deploy then this functions.mako will live at scripts/functions.mako . This is good practice as you may have multiple layouts with different script directories for each and would like to store common functionality in a single place. Defining helper functions is straight forward, lets look at functions.mako for an example: ## Helper template functions downloading/extracting files <%def name = \"setup_env()\" > if ! test -f \"/usr/local/bin/pacapt\" ; then wget -O /usr/local/bin/pacapt https://github.com/icy/pacapt/raw/ng/pacapt chmod 755 /usr/local/bin/pacapt ln -sv /usr/local/bin/pacapt /usr/local/bin/pacman || true fi </%def> <%def name = \"install_pkgs(pkgs)\" > % for pkg in pkgs: pacapt install --noconfirm ${ pkg } % endfor </%def> <%def name = \"download(url, src_file)\" > wget -O ${ src_file } ${ url } </%def> <%def name = \"extract(src, dst=None)\" > % if dst: mkdir -p ${ dst } tar -xvf ${ src } -C ${ dst } % else : tar -xvf ${ src } % endif </%def> Each %def section defines a function block that when called with any necessary arguments will output that data into the scripts with all necessary translations handled. You can see the usage of these functions in the previous example for installing elastic-agent. It is worth the time to visit Mako\u2019s website and learn about its feature set, particularly namespaces and defs and blocks .","title":"Scripting"},{"location":"user-guide/scripting/#scripting","text":"All deployments have the ability to execute scripts once a node becomes available.","title":"Scripting"},{"location":"user-guide/scripting/#before-starting","text":"A couple of things to keep in mind: All scripts are executed in order based on the filenames. It is recommended to create scripts with a numbered prefix, for example: - scripts/ - 01-install-deps - 02-configure-services There is a special reserved filename teardown , if this file exists it will only be executed during a removal of a node. This is useful for any cleanup actions that may need to be run, such as removing test users, un-enrolling from a service, etc.","title":"Before starting"},{"location":"user-guide/scripting/#writing-scripts","text":"Scripts can be written in any language, it is up to you to configure the nodes so that any runtimes and library dependencies are met on the target node for your script to execute in. One way to accomplish this is to create 01-setup-env bash script: #!/bin/bash echo \"Installing python3 on ubuntu\" sudo apt-get update sudo apt-get install -qyf python3 sudo pip install sh Then in subsequent scripts, using python3 is available. For example, in file 02-run-cmd-in-python : #!/usr/bin/env python3 import sh sh . ls ( '/' ) sh . cp ( '-a' , 'mydir' , 'anotherdir' )","title":"Writing scripts"},{"location":"user-guide/scripting/#templating","text":"OGC provides some additional capabilities through templating. Under the hood python-mako is used for the parsing. With templating, you have the ability to query the underlying database to gather node information. Because mako supports the importing of python modules and our OGC environment is already exposed, we can access our db module and use some helper methods. #!/bin/bash <%namespace name = \"db\" module = \"ogc.db\" /> echo \"\" % for node in db.by_tag ( 'sles' ) : echo \"[ID: ${ node .id } ] Name: ${ node .instance_name } || Connection: ${ node .username } @ ${ node .public_ip } || Provider: ${ node .provider } \" % endfor echo \"\" The runtime environment is also available within the template context. In one example, we can export the following into our .env file and reference those in the templates: OGC_ELASTIC_AGENT_VERSION OGC_ELASTIC_AGENT_SHA OGC_ELASTIC_AGENT_VERSION OGC_FLEET_URL OGC_FLEET_ENROLLMENT_TOKEN See the below example for downloading elastic-agent and enrolling it into a fleet server. The variable exposed to all templates for accessing the environment variables is env #!/bin/bash <%namespace name = \"utils\" file = \"/functions.mako\" /> <% url = \"https://staging.elastic.co/%s-%s/downloads/beats/elastic-agent/elastic-agent-%s-linux-x86_64.tar.gz\" % ( env [ 'OGC_ELASTIC_AGENT_VERSION' ] , env [ 'OGC_ELASTIC_AGENT_SHA' ] , env [ 'OGC_ELASTIC_AGENT_VERSION' ]) %> ${ utils .setup_env() } ${ utils .install_pkgs([ 'nano' ]) } ${ utils .download(url, 'elastic-agent.tar.gz' ) } ${ utils .extract( 'elastic-agent.tar.gz' ) } mv elastic-agent- ${ env [ 'OGC_ELASTIC_AGENT_VERSION' ] } -linux-x86_64 elastic-agent cd elastic-agent && ./elastic-agent install -f --url = ${ env [ 'OGC_FLEET_URL' ] } --enrollment-token = ${ env [ 'OGC_FLEET_ENROLLMENT_TOKEN' ] }","title":"Templating"},{"location":"user-guide/scripting/#reusable-helpers","text":"In the above example we reference a file called /functions.mako this is just another template file that sits just outside of our defined scripts , for example, if our scripts is defined to be in scripts/my_ubuntu_deploy then this functions.mako will live at scripts/functions.mako . This is good practice as you may have multiple layouts with different script directories for each and would like to store common functionality in a single place. Defining helper functions is straight forward, lets look at functions.mako for an example: ## Helper template functions downloading/extracting files <%def name = \"setup_env()\" > if ! test -f \"/usr/local/bin/pacapt\" ; then wget -O /usr/local/bin/pacapt https://github.com/icy/pacapt/raw/ng/pacapt chmod 755 /usr/local/bin/pacapt ln -sv /usr/local/bin/pacapt /usr/local/bin/pacman || true fi </%def> <%def name = \"install_pkgs(pkgs)\" > % for pkg in pkgs: pacapt install --noconfirm ${ pkg } % endfor </%def> <%def name = \"download(url, src_file)\" > wget -O ${ src_file } ${ url } </%def> <%def name = \"extract(src, dst=None)\" > % if dst: mkdir -p ${ dst } tar -xvf ${ src } -C ${ dst } % else : tar -xvf ${ src } % endif </%def> Each %def section defines a function block that when called with any necessary arguments will output that data into the scripts with all necessary translations handled. You can see the usage of these functions in the previous example for installing elastic-agent. It is worth the time to visit Mako\u2019s website and learn about its feature set, particularly namespaces and defs and blocks .","title":"Reusable helpers"}]}